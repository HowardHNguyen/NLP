{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfRZWja/5uE+sCnU9UP0Tj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HowardHNguyen/NLP/blob/main/NLP_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2qLSO8RsZDA"
      },
      "source": [
        "###11\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ461lmIsryN"
      },
      "source": [
        "corpus = ['data science professionals have promising career path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3llqqc8qNH4_",
        "outputId": "71db7fbf-c1b3-41bf-a766-96db4861e645"
      },
      "source": [
        "#2 Tokenize\n",
        "#words = corpus[0].split(\" \")\n",
        "#print(words)\n",
        "\n",
        "words = []\n",
        "for text in corpus:\n",
        "  for word in text.split(' '):\n",
        "    words.append(word)\n",
        "\n",
        "words = sorted(set(words))\n",
        "print(words)\n",
        "print('Total words = ', len(words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['career', 'data', 'have', 'path', 'professionals', 'promising', 'science']\n",
            "Total words =  7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iofe7z5jdmQM",
        "outputId": "24b6e7f1-ef0d-4638-d2e3-13e9562c76e8"
      },
      "source": [
        "#2 Tokenize - use this one\n",
        "words = corpus[0].split(\" \")\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data', 'science', 'professionals', 'have', 'promising', 'career', 'path']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ8qlhKwNHro",
        "outputId": "c8efbd2b-ca61-486d-bdfe-763003b355dc"
      },
      "source": [
        "#3 Generate word number : optional\n",
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "    word2int[word] = i\n",
        "\n",
        "print(word2int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': 0, 'science': 1, 'professionals': 2, 'have': 3, 'promising': 4, 'career': 5, 'path': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uof__HFNa3a",
        "outputId": "165feb78-ed7a-4f6d-ad10-97af781da41a"
      },
      "source": [
        "#4 Generate Skipgram\n",
        "\n",
        "WINDOW_SIZE_NUM = 3\n",
        "\n",
        "sentences = []\n",
        "for sentence in corpus:\n",
        "    sentences.append(sentence.split())\n",
        "\n",
        "for WINDOW_SIZE in np.arange (1,WINDOW_SIZE_NUM+1):\n",
        "  skipgram = []\n",
        "  for sentence in sentences:\n",
        "      for idx, word in enumerate(sentence):\n",
        "          for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
        "              if neighbor != word:\n",
        "                  skipgram.append([word, neighbor])\n",
        "\n",
        "  print('Window Size = ', WINDOW_SIZE)\n",
        "  print('Number of Entries = ',len(skipgram))\n",
        "\n",
        "  skipNgramDF = pd.DataFrame(skipgram, columns = ['input','label'])\n",
        "  print(skipNgramDF)\n",
        "  print('----------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Window Size =  1\n",
            "Number of Entries =  12\n",
            "            input          label\n",
            "0            data        science\n",
            "1         science           data\n",
            "2         science  professionals\n",
            "3   professionals        science\n",
            "4   professionals           have\n",
            "5            have  professionals\n",
            "6            have      promising\n",
            "7       promising           have\n",
            "8       promising         career\n",
            "9          career      promising\n",
            "10         career           path\n",
            "11           path         career\n",
            "----------------------------------------\n",
            "Window Size =  2\n",
            "Number of Entries =  22\n",
            "            input          label\n",
            "0            data        science\n",
            "1            data  professionals\n",
            "2         science           data\n",
            "3         science  professionals\n",
            "4         science           have\n",
            "5   professionals           data\n",
            "6   professionals        science\n",
            "7   professionals           have\n",
            "8   professionals      promising\n",
            "9            have        science\n",
            "10           have  professionals\n",
            "11           have      promising\n",
            "12           have         career\n",
            "13      promising  professionals\n",
            "14      promising           have\n",
            "15      promising         career\n",
            "16      promising           path\n",
            "17         career           have\n",
            "18         career      promising\n",
            "19         career           path\n",
            "20           path      promising\n",
            "21           path         career\n",
            "----------------------------------------\n",
            "Window Size =  3\n",
            "Number of Entries =  30\n",
            "            input          label\n",
            "0            data        science\n",
            "1            data  professionals\n",
            "2            data           have\n",
            "3         science           data\n",
            "4         science  professionals\n",
            "5         science           have\n",
            "6         science      promising\n",
            "7   professionals           data\n",
            "8   professionals        science\n",
            "9   professionals           have\n",
            "10  professionals      promising\n",
            "11  professionals         career\n",
            "12           have           data\n",
            "13           have        science\n",
            "14           have  professionals\n",
            "15           have      promising\n",
            "16           have         career\n",
            "17           have           path\n",
            "18      promising        science\n",
            "19      promising  professionals\n",
            "20      promising           have\n",
            "21      promising         career\n",
            "22      promising           path\n",
            "23         career  professionals\n",
            "24         career           have\n",
            "25         career      promising\n",
            "26         career           path\n",
            "27           path           have\n",
            "28           path      promising\n",
            "29           path         career\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-F-LmoXtxaU",
        "outputId": "6ebe732d-d0e4-4835-da45-eac81acf8c36"
      },
      "source": [
        "skipNgramDF.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MCyYl0m1iZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ba62f3-280e-4031-b65e-cd5ab64685e3"
      },
      "source": [
        "print(word2int)\n",
        "print(len(word2int))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': 0, 'science': 1, 'professionals': 2, 'have': 3, 'promising': 4, 'career': 5, 'path': 6}\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toowj8bCcCkR",
        "outputId": "57874045-d650-4ade-b439-5377b45c1c7f"
      },
      "source": [
        "# 2\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# define example\n",
        "data = ['data', \n",
        "        'data', \n",
        "        'science', \n",
        "        'science', \n",
        "        'science', \n",
        "        'professionals', \n",
        "        'professionals', \n",
        "        'professionals', \n",
        "        'professionals', \n",
        "        'have', \n",
        "        'have', \n",
        "        'have', \n",
        "        'have', \n",
        "        'promising', \n",
        "        'promising', \n",
        "        'promising', \n",
        "        'promising', \n",
        "        'career', \n",
        "        'career', \n",
        "        'career', \n",
        "        'path', \n",
        "        'path'\n",
        "        ]\n",
        "values = array(data)\n",
        "print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data' 'data' 'science' 'science' 'science' 'professionals'\n",
            " 'professionals' 'professionals' 'professionals' 'have' 'have' 'have'\n",
            " 'have' 'promising' 'promising' 'promising' 'promising' 'career' 'career'\n",
            " 'career' 'path' 'path']\n",
            "[1 1 6 6 6 4 4 4 4 2 2 2 2 5 5 5 5 0 0 0 3 3]\n",
            "[[0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]]\n",
            "['data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1Oc2zPlcCeV",
        "outputId": "fb781682-5d8e-41f7-e777-4bac5bae484d"
      },
      "source": [
        "# 2b\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# define example\n",
        "data_label = [\n",
        "              'science', \n",
        "              'professionals', \n",
        "              'data', \n",
        "              'professionals', \n",
        "              'have', \n",
        "              'data', \n",
        "              'science', \n",
        "              'have', \n",
        "              'promising', \n",
        "              'science', \n",
        "              'professionals',\n",
        "              'promising', \n",
        "              'career', \n",
        "              'professionals',\n",
        "              'have', \n",
        "              'career', \n",
        "              'path',\n",
        "              'have',\n",
        "              'promising', \n",
        "              'path',\n",
        "              'promising', \n",
        "              'career'\n",
        "              ]\n",
        "values = array(data_label)\n",
        "print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['science' 'professionals' 'data' 'professionals' 'have' 'data' 'science'\n",
            " 'have' 'promising' 'science' 'professionals' 'promising' 'career'\n",
            " 'professionals' 'have' 'career' 'path' 'have' 'promising' 'path'\n",
            " 'promising' 'career']\n",
            "[6 4 1 4 2 1 6 2 5 6 4 5 0 4 2 0 3 2 5 3 5 0]\n",
            "[[0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]]\n",
            "['science']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrABV87ucCaT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhgRqDiWcCWZ"
      },
      "source": [
        "# problem #3 by Gensim Code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlhX-_3JVMaR",
        "outputId": "11a24c08-ea4b-4ba7-8737-ff1df25e389b"
      },
      "source": [
        "corpus = ['I like deep learning',\n",
        "          'I like NLP',\n",
        "          'I enjoy flying']\n",
        "\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I like deep learning', 'I like NLP', 'I enjoy flying']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUU0MtoKEYlb",
        "outputId": "48abae36-6a59-4ede-b295-9a5a27c2a450"
      },
      "source": [
        "# remove stop words - no need\n",
        "# tokenize\n",
        "sentences = []\n",
        "for sentence in corpus:\n",
        "  sentences.append(sentence.split())\n",
        "\n",
        "print(sentences)\n",
        "print(len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['I', 'like', 'deep', 'learning'], ['I', 'like', 'NLP'], ['I', 'enjoy', 'flying']]\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWKUO0DVFCJ9"
      },
      "source": [
        "#load Gensim library\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.callbacks import CallbackAny2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIpKzuEKFeat"
      },
      "source": [
        "# build W2v model\n",
        "\n",
        "# init call back\n",
        "\n",
        "class callback(CallbackAny2Vec):\n",
        "  \"\"\"\n",
        "  Callback to print loss after each epoch\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.epoch = 0\n",
        "  def on_epoch_end(self, model):\n",
        "    loss = model.get_latest_training_loss()\n",
        "\n",
        "    if self.epoch == 0:\n",
        "      print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "    elif self.epoch % 100 == 0:\n",
        "      print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "\n",
        "    self.epoch += 1\n",
        "    self.loss_previous_step = loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bisnU2plRel1",
        "outputId": "86a44967-7c94-4b19-9ca5-fed7d5900dfd"
      },
      "source": [
        "# init w2v class\n",
        "\n",
        "w2v_model = Word2Vec(size = 300,\n",
        "                     window = 2,\n",
        "                     min_count = 0,\n",
        "                     workers = 20,\n",
        "                     sg = 1,\n",
        "                     negative = 5,\n",
        "                     sample = 1e-5)\n",
        "print(w2v_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=0, size=300, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW6mjSCjR3p0",
        "outputId": "0181de4f-18bb-4fe2-f2ff-5c140b4166a3"
      },
      "source": [
        "#build vocab\n",
        "words = w2v_model.build_vocab(sentences)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtbngpPLSClc",
        "outputId": "b82126bd-c7e4-4ee5-ec8f-ba789019f59e"
      },
      "source": [
        "# train the w2v model\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "w2v_model.train(sentences,\n",
        "                total_examples = w2v_model.corpus_count,\n",
        "                epochs = 1001,\n",
        "                report_delay = 1,\n",
        "                compute_loss = True,\n",
        "                callbacks = [callback()])\n",
        "end = time.time()\n",
        "print(\"elapsed time in second:\" + str(end - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss after epoch 0: 0.0\n",
            "Loss after epoch 100: 0.0\n",
            "Loss after epoch 200: 0.0\n",
            "Loss after epoch 300: 0.0\n",
            "Loss after epoch 400: 0.0\n",
            "Loss after epoch 500: 0.0\n",
            "Loss after epoch 600: 0.0\n",
            "Loss after epoch 700: 0.0\n",
            "Loss after epoch 800: 0.0\n",
            "Loss after epoch 900: 0.0\n",
            "Loss after epoch 1000: 0.0\n",
            "elapsed time in second:7.559913158416748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0TEkJwCS1Qt",
        "outputId": "97e7106a-5499-4554-a56d-d511509a02b2"
      },
      "source": [
        "# print the vocabulary\n",
        "\n",
        "words = list(w2v_model.wv.vocab)\n",
        "print(words)\n",
        "print('Vocab size: '+str(len(words)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'like', 'deep', 'learning', 'NLP', 'enjoy', 'flying']\n",
            "Vocab size: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFt5d-piTOnk",
        "outputId": "b496fb57-f36c-45f2-a246-d28f1b9c3125"
      },
      "source": [
        "# compute similarity\n",
        "\n",
        "w1 = 'enjoy'\n",
        "w2v_model.wv.most_similar(positive = w1, topn = 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 0.03126328065991402),\n",
              " ('like', 0.014957636594772339),\n",
              " ('learning', 0.007483895868062973)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW3HdRWFToA9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}