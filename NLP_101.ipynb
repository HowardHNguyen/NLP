{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx2Vtax9cyiHiDietvsuAs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HowardHNguyen/Natural_Language_Processing-NLP/blob/main/NLP_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import time\n",
        "import spacy\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GPNw1Qx5RLG",
        "outputId": "f202c26a-4868-4b52-bc95-5d63084eeea4"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
      ],
      "metadata": {
        "id": "j7rzTAdWPsw_"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "gztabxVS5RHx"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_file(filename):\n",
        "    file = open(filename, \"r\", encoding=\"utf-8\")\n",
        "    return file.read()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return text\n",
        "\n",
        "def divide_into_sentences_nltk(text):\n",
        "    sentences = tokenizer.tokenize(text)\n",
        "    return sentences\n",
        "\n",
        "def divide_into_sentences_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    return [sentence.text for sentence in doc.sents]\n",
        "\n",
        "def divide_into_sentences(text):\n",
        "    return divide_into_sentences_nltk(text)"
      ],
      "metadata": {
        "id": "n1kPixl-5RE2"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC2xfaBA5tEw",
        "outputId": "8d166048-1122-456b-a9e2-8b73e4e470b0"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/drive/MyDrive/_Python/Python-Natural-Language-Processing/Chapter01/sherlock_holmes_1.txt\"\n",
        "file = open(filename, \"r\", encoding=\"utf-8\")\n",
        "text = file.read()"
      ],
      "metadata": {
        "id": "1k0l-xJB5tA3"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "_r-1idprSHXD",
        "outputId": "677982d5-3a15-474b-923a-0e0bf8ca977d"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To Sherlock Holmes she is always _the_ woman. I have seldom heard him\\nmention her under any other name. In his eyes she eclipses and\\npredominates the whole of her sex. It was not that he felt any emotion\\nakin to love for Irene Adler. All emotions, and that one particularly,\\nwere abhorrent to his cold, precise but admirably balanced mind. He\\nwas, I take it, the most perfect reasoning and observing machine that\\nthe world has seen, but as a lover he would have placed himself in a\\nfalse position. He never spoke of the softer passions, save with a gibe\\nand a sneer. They were admirable things for the observer—excellent for\\ndrawing the veil from men’s motives and actions. But for the trained\\nreasoner to admit such intrusions into his own delicate and finely\\nadjusted temperament was to introduce a distracting factor which might\\nthrow a doubt upon all his mental results. Grit in a sensitive\\ninstrument, or a crack in one of his own high-power lenses, would not\\nbe more disturbing than a strong emotion in a nature such as his. And\\nyet there was but one woman to him, and that woman was the late Irene\\nAdler, of dubious and questionable memory.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace newlines with spaces\n",
        "text = text.replace(\"\\n\", \" \")"
      ],
      "metadata": {
        "id": "Nv4cxKK45RBL"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize an NLTK tokenizer. This uses the punkt model we downloaded earlier\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
      ],
      "metadata": {
        "id": "tvzqJug55xu7"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide the text into sentences\n",
        "sentences = tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "azLTgWAw5xrW"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here is the results:\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocU0RgNg5xns",
        "outputId": "48a857dd-0ab8-4e5d-f1d5-de6ef1938788"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['To Sherlock Holmes she is always _the_ woman.',\n",
              " 'I have seldom heard him mention her under any other name.',\n",
              " 'In his eyes she eclipses and predominates the whole of her sex.',\n",
              " 'It was not that he felt any emotion akin to love for Irene Adler.',\n",
              " 'All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.',\n",
              " 'He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position.',\n",
              " 'He never spoke of the softer passions, save with a gibe and a sneer.',\n",
              " 'They were admirable things for the observer—excellent for drawing the veil from men’s motives and actions.',\n",
              " 'But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results.',\n",
              " 'Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his.',\n",
              " 'And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.']"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividing sentences into words - Tokenization\n",
        "In many instances, we rely on individual words when we do NLP tasks. This happens, for example, when we build semantic models of texts by relying on the semantics of individual words, or when we are looking for words with a specific part of speech. To divide text into words, we can use NLTK and spaCy."
      ],
      "metadata": {
        "id": "_W51K3dOS__x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from previous steps to the 'sentences'\n",
        "words = nltk.tokenize.word_tokenize(text)"
      ],
      "metadata": {
        "id": "GlPGj9QY5FSL"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the results of tokenize words\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hwb2tcSTcTI",
        "outputId": "eafbbfb6-02e9-44c6-f1c2-4eee617104e9"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['To', 'Sherlock', 'Holmes', 'she', 'is', 'always', '_the_', 'woman', '.', 'I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', '.', 'In', 'his', 'eyes', 'she', 'eclipses', 'and', 'predominates', 'the', 'whole', 'of', 'her', 'sex', '.', 'It', 'was', 'not', 'that', 'he', 'felt', 'any', 'emotion', 'akin', 'to', 'love', 'for', 'Irene', 'Adler', '.', 'All', 'emotions', ',', 'and', 'that', 'one', 'particularly', ',', 'were', 'abhorrent', 'to', 'his', 'cold', ',', 'precise', 'but', 'admirably', 'balanced', 'mind', '.', 'He', 'was', ',', 'I', 'take', 'it', ',', 'the', 'most', 'perfect', 'reasoning', 'and', 'observing', 'machine', 'that', 'the', 'world', 'has', 'seen', ',', 'but', 'as', 'a', 'lover', 'he', 'would', 'have', 'placed', 'himself', 'in', 'a', 'false', 'position', '.', 'He', 'never', 'spoke', 'of', 'the', 'softer', 'passions', ',', 'save', 'with', 'a', 'gibe', 'and', 'a', 'sneer', '.', 'They', 'were', 'admirable', 'things', 'for', 'the', 'observer—excellent', 'for', 'drawing', 'the', 'veil', 'from', 'men', '’', 's', 'motives', 'and', 'actions', '.', 'But', 'for', 'the', 'trained', 'reasoner', 'to', 'admit', 'such', 'intrusions', 'into', 'his', 'own', 'delicate', 'and', 'finely', 'adjusted', 'temperament', 'was', 'to', 'introduce', 'a', 'distracting', 'factor', 'which', 'might', 'throw', 'a', 'doubt', 'upon', 'all', 'his', 'mental', 'results', '.', 'Grit', 'in', 'a', 'sensitive', 'instrument', ',', 'or', 'a', 'crack', 'in', 'one', 'of', 'his', 'own', 'high-power', 'lenses', ',', 'would', 'not', 'be', 'more', 'disturbing', 'than', 'a', 'strong', 'emotion', 'in', 'a', 'nature', 'such', 'as', 'his', '.', 'And', 'yet', 'there', 'was', 'but', 'one', 'woman', 'to', 'him', ',', 'and', 'that', 'woman', 'was', 'the', 'late', 'Irene', 'Adler', ',', 'of', 'dubious', 'and', 'questionable', 'memory', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YedMyQj0U6PA",
        "outputId": "e0a98746-3d29-4f88-e480-31d347232820"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vpDvqDcU8eS",
        "outputId": "4a49651c-352b-4746-e888-96136bb31ae9"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the stopwords\n",
        "words = [word for word in words if word not in stop_words]"
      ],
      "metadata": {
        "id": "eFyNYZM1Th3F"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRLvY6M5UiPh",
        "outputId": "564168c1-c4b8-45a9-8a4b-5ff9766380a8"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['To', 'Sherlock', 'Holmes', 'always', '_the_', 'woman', '.', 'I', 'seldom', 'heard', 'mention', 'name', '.', 'In', 'eyes', 'eclipses', 'predominates', 'whole', 'sex', '.', 'It', 'felt', 'emotion', 'akin', 'love', 'Irene', 'Adler', '.', 'All', 'emotions', ',', 'one', 'particularly', ',', 'abhorrent', 'cold', ',', 'precise', 'admirably', 'balanced', 'mind', '.', 'He', ',', 'I', 'take', ',', 'perfect', 'reasoning', 'observing', 'machine', 'world', 'seen', ',', 'lover', 'would', 'placed', 'false', 'position', '.', 'He', 'never', 'spoke', 'softer', 'passions', ',', 'save', 'gibe', 'sneer', '.', 'They', 'admirable', 'things', 'observer—excellent', 'drawing', 'veil', 'men', '’', 'motives', 'actions', '.', 'But', 'trained', 'reasoner', 'admit', 'intrusions', 'delicate', 'finely', 'adjusted', 'temperament', 'introduce', 'distracting', 'factor', 'might', 'throw', 'doubt', 'upon', 'mental', 'results', '.', 'Grit', 'sensitive', 'instrument', ',', 'crack', 'one', 'high-power', 'lenses', ',', 'would', 'disturbing', 'strong', 'emotion', 'nature', '.', 'And', 'yet', 'one', 'woman', ',', 'woman', 'late', 'Irene', 'Adler', ',', 'dubious', 'questionable', 'memory', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "tPUZldVeVZpA"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "ZQaXntTJG9_w"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalization (convert to lowercase)\n",
        "token_lower = [word.lower() for word in tokens]"
      ],
      "metadata": {
        "id": "rpZVvIZgHDpg"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counting words\n",
        "word_counts = Counter(token_lower)"
      ],
      "metadata": {
        "id": "rznCJr6oHRin"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print word counts\n",
        "for word, count in word_counts.most_common(10):\n",
        "    print(word, count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH1kxOxsHYDp",
        "outputId": "e4c8eec2-6596-4cff-944c-e54f4f7da715"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". 11\n",
            ", 11\n",
            "a 10\n",
            "and 9\n",
            "the 8\n",
            "to 6\n",
            "his 6\n",
            "in 5\n",
            "was 5\n",
            "of 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, count in word_counts.items():\n",
        "    print(f\"{word}, {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZODz2OsHdZ_",
        "outputId": "61d08122-5aae-4879-b4a6-570271cf0b99"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to, 6\n",
            "sherlock, 1\n",
            "holmes, 1\n",
            "she, 2\n",
            "is, 1\n",
            "always, 1\n",
            "_the_, 1\n",
            "woman, 3\n",
            "., 11\n",
            "i, 2\n",
            "have, 2\n",
            "seldom, 1\n",
            "heard, 1\n",
            "him, 2\n",
            "mention, 1\n",
            "her, 2\n",
            "under, 1\n",
            "any, 2\n",
            "other, 1\n",
            "name, 1\n",
            "in, 5\n",
            "his, 6\n",
            "eyes, 1\n",
            "eclipses, 1\n",
            "and, 9\n",
            "predominates, 1\n",
            "the, 8\n",
            "whole, 1\n",
            "of, 4\n",
            "sex, 1\n",
            "it, 2\n",
            "was, 5\n",
            "not, 2\n",
            "that, 4\n",
            "he, 4\n",
            "felt, 1\n",
            "emotion, 2\n",
            "akin, 1\n",
            "love, 1\n",
            "for, 4\n",
            "irene, 2\n",
            "adler, 2\n",
            "all, 2\n",
            "emotions, 1\n",
            ",, 11\n",
            "one, 3\n",
            "particularly, 1\n",
            "were, 2\n",
            "abhorrent, 1\n",
            "cold, 1\n",
            "precise, 1\n",
            "but, 4\n",
            "admirably, 1\n",
            "balanced, 1\n",
            "mind, 1\n",
            "take, 1\n",
            "most, 1\n",
            "perfect, 1\n",
            "reasoning, 1\n",
            "observing, 1\n",
            "machine, 1\n",
            "world, 1\n",
            "has, 1\n",
            "seen, 1\n",
            "as, 2\n",
            "a, 10\n",
            "lover, 1\n",
            "would, 2\n",
            "placed, 1\n",
            "himself, 1\n",
            "false, 1\n",
            "position, 1\n",
            "never, 1\n",
            "spoke, 1\n",
            "softer, 1\n",
            "passions, 1\n",
            "save, 1\n",
            "with, 1\n",
            "gibe, 1\n",
            "sneer, 1\n",
            "they, 1\n",
            "admirable, 1\n",
            "things, 1\n",
            "observer—excellent, 1\n",
            "drawing, 1\n",
            "veil, 1\n",
            "from, 1\n",
            "men, 1\n",
            "’, 1\n",
            "s, 1\n",
            "motives, 1\n",
            "actions, 1\n",
            "trained, 1\n",
            "reasoner, 1\n",
            "admit, 1\n",
            "such, 2\n",
            "intrusions, 1\n",
            "into, 1\n",
            "own, 2\n",
            "delicate, 1\n",
            "finely, 1\n",
            "adjusted, 1\n",
            "temperament, 1\n",
            "introduce, 1\n",
            "distracting, 1\n",
            "factor, 1\n",
            "which, 1\n",
            "might, 1\n",
            "throw, 1\n",
            "doubt, 1\n",
            "upon, 1\n",
            "mental, 1\n",
            "results, 1\n",
            "grit, 1\n",
            "sensitive, 1\n",
            "instrument, 1\n",
            "or, 1\n",
            "crack, 1\n",
            "high-power, 1\n",
            "lenses, 1\n",
            "be, 1\n",
            "more, 1\n",
            "disturbing, 1\n",
            "than, 1\n",
            "strong, 1\n",
            "nature, 1\n",
            "yet, 1\n",
            "there, 1\n",
            "late, 1\n",
            "dubious, 1\n",
            "questionable, 1\n",
            "memory, 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "words, counts = zip(*word_counts.most_common(30))\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(words, counts)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(\"Top 30 words in Sherlock Holmes\")\n",
        "plt.xlabel(\"Words\")\n",
        "plt.ylabel(\"Counts\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "pXj8uHtoH5Ws",
        "outputId": "e2b16bca-d7f1-4a25-be0b-5e1437840bf5"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB2SElEQVR4nO3dd3gU1dvG8WdpCQRCJ/QkBELvodfQqxRpIr0FpaN0pQoIKiIoIChFpfcOYug9EAFBpAiBIL2GlgDJ8/6Rd+eXNZSUnRT8fq6LS3d2ds7Zye7s3HPKWFRVBQAAAAAA2F2S+K4AAAAAAABvK0I3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAHFo9OjRYrFY7LItNzc36dSpk122FR0BAQFisVjkyy+/jJPy5s+fLxaLRQICAkzZfqdOnSR16tSmbDs24uvvCwCwL0I3APyHWCyWKP3buXOnqfV4+vSpdO3aVYoUKSJp06aV1KlTS/HixeWbb76R58+fR1r//v370qNHD8mcObM4OTmJt7e3+Pv7m1rH/6q9e/dK/fr1JUeOHOLo6Ci5c+eWxo0by6JFi+K7agmS9SLK7du3X/q8m5ubNGrUKI5rBQBISJLFdwUAAHHn559/tnn8008/ybZt2yItL1iwoKn1ePr0qZw6dUoaNGggbm5ukiRJEtm/f78MGDBADh06ZBPwwsLCpGHDhnL8+HEZNGiQZMqUSWbMmCHVq1eXo0ePSr58+Uyta0J25swZSZLEftfPly9fLq1bt5YSJUpIv379JH369HLx4kXZvXu3zJkzR9q2bWu3sgAA+K8gdAPAf0i7du1sHh88eFC2bdsWabnZMmTIIAcPHrRZ1rNnT0mbNq18++23MmXKFMmaNauIiKxYsUL2798vy5cvlxYtWoiISKtWrcTT01NGjRqV4FpgX7x4IWFhYZIiRQrTy3JwcLDr9kaPHi2FChWSgwcPRqr/zZs37VpWVDx+/FicnJzivFwAAOyJ7uUAABuPHz+Wjz76SHLlyiUODg6SP39++fLLL0VVbdazWCzSu3dvWbhwoeTPn18cHR2ldOnSsnv37hiX7ebmJiLh3cmtVqxYIS4uLtK8eXNjWebMmaVVq1aydu1aCQkJeeX2Bg4cKBkzZrSpe58+fcRisci0adOMZTdu3BCLxSIzZ840lt28eVO6du0qLi4u4ujoKMWLF5cFCxbYbD/i2OapU6eKh4eHODg4yJ9//iki4V21y5QpI46OjuLh4SHff//9S+u5bds2qVy5sqRLl05Sp04t+fPnl+HDh0dpf0Uc82sd+7xv3z4ZOHCg0R2/WbNmcuvWrTdu7++//5YyZcq89IJBlixZXvqa2bNnG++7TJky4ufnF2mdv/76S1q0aCEZMmQQR0dH8fLyknXr1tmsY637rl275MMPP5QsWbJIzpw5X1vfGTNmSOHChcXBwUGyZ88uvXr1svnsWB06dEgaNGgg6dOnFycnJylWrJh88803r932sWPHJHPmzFK9enV59OjRa9eNrqh+x/7Nuo/27t0rffv2lcyZM0u6dOnEx8dHnj17Jvfv35cOHTpI+vTpJX369DJ48OBI2wwLC5OpU6dK4cKFxdHRUVxcXMTHx0fu3btns96RI0ekbt26kilTJkmZMqW4u7tLly5d7LofAOC/gpZuAIBBVeWdd96RHTt2SNeuXaVEiRKydetWGTRokPzzzz/y9ddf26y/a9cuWbp0qfTt21ccHBxkxowZUq9ePTl8+LAUKVLkjeU9e/ZMgoKC5OnTp3LkyBH58ssvxdXVVfLmzWus8/vvv0upUqUidaMuW7aszJ49W86ePStFixZ96farVKkiX3/9tZw6dcqoz549eyRJkiSyZ88e6du3r7FMRKRq1aoiEt79vXr16nL+/Hnp3bu3uLu7y/Lly6VTp05y//596devn0058+bNk+DgYOnRo4c4ODhIhgwZ5I8//pA6depI5syZZfTo0fLixQsZNWqUuLi42Lz21KlT0qhRIylWrJiMHTtWHBwc5Pz587Jv37437r9X6dOnj6RPn15GjRolAQEBMnXqVOndu7csXbr0ta9zdXUVX19fuXLlyhsDr4jIokWL5OHDh+Lj4yMWi0UmT54szZs3lwsXLkjy5MmN91epUiXJkSOHDB06VJycnGTZsmXStGlTWblypTRr1sxmmx9++KFkzpxZRo4cKY8fP35l2aNHj5YxY8ZIrVq15IMPPpAzZ87IzJkzxc/PT/bt22eUv23bNmnUqJFky5ZN+vXrJ1mzZpXTp0/Lhg0bIv0drfz8/KRu3bri5eUla9eulZQpU75xX9y9e/ely8PCwmweR/c79jJ9+vSRrFmzypgxY+TgwYMye/ZsSZcunezfv19y584tEyZMkE2bNskXX3whRYoUkQ4dOhiv9fHxkfnz50vnzp2lb9++cvHiRfn222/l999/N/bbzZs3jc/u0KFDJV26dBIQECCrVq16Y90AAC+hAID/rF69emnEn4I1a9aoiOhnn31ms16LFi3UYrHo+fPnjWUioiKiR44cMZZdunRJHR0dtVmzZlEqf/HixcZ2RES9vLz0xIkTNus4OTlply5dIr1248aNKiK6ZcuWV27/5s2bKiI6Y8YMVVW9f/++JkmSRFu2bKkuLi7Gen379tUMGTJoWFiYqqpOnTpVRUR/+eUXY51nz55phQoVNHXq1BoUFKSqqhcvXlQRUWdnZ71586ZN2U2bNlVHR0e9dOmSsezPP//UpEmT2uzzr7/+WkVEb9269cb99W+urq7asWNH4/G8efNURLRWrVrGe1FVHTBggCZNmlTv37//2u39+OOPKiKaIkUK9fb21k8//VT37NmjoaGhNutZ33fGjBn17t27xvK1a9eqiOj69euNZTVr1tSiRYtqcHCwsSwsLEwrVqyo+fLli1T3ypUr64sXL2zKsz538eJFVQ3/u6ZIkULr1KljU7dvv/1WRUTnzp2rqqovXrxQd3d3dXV11Xv37tlsM+L+6dixozo5Oamq6t69e9XZ2VkbNmxoU+dXGTVqlM1n+GX/GjZsaKwfne/Yq/6+devWtal/hQoV1GKxaM+ePY1lL1680Jw5c2q1atWMZXv27FER0YULF9qUvWXLFpvlq1evVhFRPz+/N75/AMCb0b0cAGDYtGmTJE2a1GgBtvroo49EVWXz5s02yytUqCClS5c2HufOnVuaNGkiW7duldDQ0DeW5+3tLdu2bZPly5dLz549JXny5JFaN58+ffrSscuOjo7G86+SOXNmKVCggNHlfd++fZI0aVIZNGiQ3LhxQ86dOyci4S3dlStXNm7ltWnTJsmaNau89957xraSJ08uffv2lUePHsmuXbtsynn33Xclc+bMxuPQ0FDZunWrNG3aVHLnzm0sL1iwoNStW9fmtenSpRMRkbVr10ZqFY2pHj162NyWrEqVKhIaGiqXLl167eu6dOkiW7ZskerVq8vevXtl3LhxUqVKFcmXL5/s378/0vqtW7eW9OnT25QjInLhwgURCW/93b59u7Rq1UoePnwot2/fltu3b8udO3ekbt26cu7cOfnnn39sttm9e3dJmjTpa+v522+/ybNnz6R///42PSC6d+8uzs7OsnHjRhEJ7yVx8eJF6d+/v7GfrV5227YdO3ZI3bp1pWbNmrJq1apojZlfuXKlbNu2LdK/f/dsiO537GW6du1qU/9y5cqJqkrXrl2NZUmTJhUvLy/jbyESPlFe2rRppXbt2sbf4vbt21K6dGlJnTq17NixQ0T+95ncsGHDS+8mAACIHkI3AMBw6dIlyZ49u6RJk8ZmuXU283+HtpfNHO7p6SlPnjyJ0hhiFxcXqVWrlrRo0UJmzpwpjRo1ktq1a8v169eNdVKmTPnScdvBwcHG869TpUoVo/v4nj17xMvLS7y8vCRDhgyyZ88eCQoKkuPHjxuB0fo+8+XLF6lL+6v2g7u7u83jW7duydOnT1+6f/Lnz2/zuHXr1lKpUiXp1q2buLi4SJs2bWTZsmWxCuARg76IGMH43+N2X6Zu3bqydetWuX//vuzevVt69eolly5dkkaNGkWaTO1N5Zw/f15UVT799FPJnDmzzb9Ro0aJSOQJ2v69L1/Guv//vS9TpEghefLkMZ7/+++/RUSiNNQhODhYGjZsKCVLlpRly5ZFeyK8qlWrSq1atSL9s14cilj36HzHXubf+z1t2rQiIpIrV65IyyP+zc+dOycPHjyQLFmyRPp7PHr0yPhbVKtWTd59910ZM2aMZMqUSZo0aSLz5s177fwJAIBXY0w3ACDBaNGihYwYMULWrl0rPj4+IiKSLVs2uXbtWqR1rcuyZ8/+2m1WrlxZ5syZIxcuXJA9e/ZIlSpVxGKxSOXKlWXPnj2SPXt2CQsLswnd0RWVMb+ve+3u3btlx44dsnHjRtmyZYssXbpUatSoIb/++usbW31f5lWv0TdM1BVRqlSppEqVKlKlShXJlCmTjBkzRjZv3iwdO3aMcjnWCwcff/xxpBZ+q4jj90Vity9jw8HBQRo0aCBr166VLVu2JOh7a79qv79secS/eVhYmGTJkkUWLlz40tdbe2tYLBZZsWKFHDx4UNavXy9bt26VLl26yFdffSUHDx6U1KlT2+FdAMB/By3dAACDq6urXL16VR4+fGiz/K+//jKej8jaPTuis2fPSqpUqWy6W0eVtav4gwcPjGUlSpQQf3//SC2/hw4dklSpUomnp+drt2kN09u2bRM/Pz/jcdWqVWXPnj2yZ88ecXJysukm7+rqKufOnYtU5qv2w79lzpxZUqZM+dL9c+bMmUjLkiRJIjVr1pQpU6bIn3/+KePHj5ft27cb3X3jm5eXl4jISy9+vE6ePHlEJLxr/stagWvVqhWpxTcqrPv/3/vy2bNncvHiReN5Dw8PERE5efLkG7dpsVhk4cKFUrNmTWnZsqXs3Lkz2vWKiuh+x+zJw8ND7ty5I5UqVXrp36J48eI265cvX17Gjx8vR44ckYULF8qpU6dkyZIlptUPAN5WhG4AgKFBgwYSGhoq3377rc3yr7/+WiwWi9SvX99m+YEDB8Tf3994HBgYKGvXrpU6deq8toX29u3bL211/eGHH0TkfyFPJLz1+8aNGzYzJ9++fVuWL18ujRs3fuO4W3d3d8mRI4d8/fXX8vz5c6lUqZKIhIfxv//+W1asWCHly5eXZMn+1/mrQYMGcv36dZvZvl+8eCHTp0+X1KlTS7Vq1V5bZtKkSaVu3bqyZs0auXz5srH89OnTsnXrVpt1XzbrdYkSJURE4rw7r6+v70uXb9q0SUQid+d+kyxZskj16tXl+++/f2lgj8oQhJepVauWpEiRQqZNm2bzOfrxxx/lwYMH0rBhQxERKVWqlLi7u8vUqVMj3UrsZZ+/FClSyKpVq6RMmTLSuHFjOXz4cIzq9zrR/Y7ZU6tWrSQ0NFTGjRsX6bkXL14Y++jevXuR9k98fSYB4G1A93IAgKFx48bi7e0tI0aMkICAAClevLj8+uuvsnbtWunfv7/RcmhVpEgRqVu3rs0tw0RExowZ89pyfvnlF5k1a5Y0bdpU8uTJIw8fPpStW7fKtm3bpHHjxlKjRg1j3RYtWkj58uWlc+fO8ueff0qmTJlkxowZEhoa+sZyrKpUqSJLliyRokWLGuOOS5UqJU5OTnL27Flp27atzfo9evSQ77//Xjp16iRHjx4VNzc3WbFihezbt0+mTp0apdbZMWPGyJYtW6RKlSry4YcfGqG9cOHCcuLECWO9sWPHyu7du6Vhw4bi6uoqN2/elBkzZkjOnDmlcuXKUXp/9tKkSRNxd3eXxo0bi4eHhzx+/Fh+++03Wb9+vRFEo+u7776TypUrS9GiRaV79+6SJ08euXHjhhw4cECuXLkix48fj/Y2M2fOLMOGDZMxY8ZIvXr15J133pEzZ87IjBkzpEyZMtKuXTsRCe9BMHPmTGncuLGUKFFCOnfuLNmyZZO//vpLTp06FekCiEh49/YNGzZIjRo1pH79+rJr164ojQmPquh+x+ypWrVq4uPjIxMnTpRjx45JnTp1JHny5HLu3DlZvny5fPPNN9KiRQtZsGCBzJgxQ5o1ayYeHh7y8OFDmTNnjjg7O0uDBg1Mqx8AvK0I3QAAQ5IkSWTdunUycuRIWbp0qcybN0/c3Nzkiy++kI8++ijS+tWqVZMKFSrImDFj5PLly1KoUCGZP3++FCtW7LXlVK5cWfbv3y+LFy+WGzduSLJkySR//vwyZcoU6dOnj826SZMmlU2bNsmgQYNk2rRp8vTpUylTpozMnz8/yi2v1tAdMcQmS5ZMKlSoIL/99luk8dwpU6aUnTt3ytChQ2XBggUSFBQk+fPnl3nz5kmnTp2iVGaxYsVk69atMnDgQBk5cqTkzJlTxowZI9euXbMJ3e+8844EBATI3Llz5fbt25IpUyapVq2ajBkzxpggK6788MMPsnbtWlm2bJlcvXpVVFXy5MkjI0aMkCFDhtj0BoiqQoUKyZEjR2TMmDEyf/58uXPnjmTJkkVKliwpI0eOjHFdR48eLZkzZ5Zvv/1WBgwYIBkyZJAePXrIhAkTjHt0i4RPDLdjxw4ZM2aMfPXVVxIWFiYeHh7SvXv3V27b2dlZtm7dKlWrVpXatWvLnj17Io09j6nofsfsbdasWVK6dGn5/vvvZfjw4ZIsWTJxc3OTdu3aGb1AqlWrJocPH5YlS5bIjRs3JG3atFK2bFlZuHBhlCa6AwDYsmh0ZlUBAOD/WSwW6dWrV6RusgAAAPgfxnQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBImUgMAxAhTggAAALwZLd0AAAAAAJiE0A0AAAAAgEne+u7lYWFhcvXqVUmTJo1YLJb4rg4AAAAA4C2gqvLw4UPJnj27JEny6vbstz50X716VXLlyhXf1QAAAAAAvIUCAwMlZ86cr3z+rQ/dadKkEZHwHeHs7BzPtQEAAAAAvA2CgoIkV65cRuZ8lbc+dFu7lDs7OxO6AQAAAAB29aZhzEykBgAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJksV3BfA/bkM3mrLdgM8bxml5rysTAAAAAP5LaOkGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAEwSr6F79+7d0rhxY8mePbtYLBZZs2aNzfOqKiNHjpRs2bJJypQppVatWnLu3Ln4qSwAAAAAANEUr6H78ePHUrx4cfnuu+9e+vzkyZNl2rRpMmvWLDl06JA4OTlJ3bp1JTg4OI5rCgAAAABA9CWLz8Lr168v9evXf+lzqipTp06VTz75RJo0aSIiIj/99JO4uLjImjVrpE2bNnFZVQAAAAAAoi3Bjum+ePGiXL9+XWrVqmUsS5s2rZQrV04OHDgQjzUDAAAAACBq4rWl+3WuX78uIiIuLi42y11cXIznXiYkJERCQkKMx0FBQeZUEAAAAACAN0iwoTumJk6cKGPGjInvauAl3IZuNG3bAZ83NG3bAAAAABBTCbZ7edasWUVE5MaNGzbLb9y4YTz3MsOGDZMHDx4Y/wIDA02tJwAAAAAAr5JgQ7e7u7tkzZpVfH19jWVBQUFy6NAhqVChwitf5+DgIM7Ozjb/AAAAAACID/HavfzRo0dy/vx54/HFixfl2LFjkiFDBsmdO7f0799fPvvsM8mXL5+4u7vLp59+KtmzZ5emTZvGX6UBAAAAAIiieA3dR44cEW9vb+PxwIEDRUSkY8eOMn/+fBk8eLA8fvxYevToIffv35fKlSvLli1bxNHRMb6qDAAAAABAlMVr6K5evbqo6iuft1gsMnbsWBk7dmwc1goAAAAAAPtIsGO6AQAAAABI7AjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYJFl8VwAwi9vQjaZtO+DzhqZtGwAAAMDbg5ZuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkCTp0h4aGyqeffiru7u6SMmVK8fDwkHHjxomqxnfVAAAAAAB4o2TxXYHXmTRpksycOVMWLFgghQsXliNHjkjnzp0lbdq00rdv3/iuHgAAAAAAr5WgQ/f+/fulSZMm0rBhQxERcXNzk8WLF8vhw4fjuWYAAAAAALxZgu5eXrFiRfH19ZWzZ8+KiMjx48dl7969Ur9+/Ve+JiQkRIKCgmz+AQAAAAAQHxJ0S/fQoUMlKChIChQoIEmTJpXQ0FAZP368vP/++698zcSJE2XMmDFxWEvgf9yGbjRluwGfNzRluwAAAADMlaBbupctWyYLFy6URYsWib+/vyxYsEC+/PJLWbBgwStfM2zYMHnw4IHxLzAwMA5rDAAAAADA/yTolu5BgwbJ0KFDpU2bNiIiUrRoUbl06ZJMnDhROnbs+NLXODg4iIODQ1xWEwAAAACAl0rQLd1PnjyRJElsq5g0aVIJCwuLpxoBAAAAABB1Cbqlu3HjxjJ+/HjJnTu3FC5cWH7//XeZMmWKdOnSJb6rBgAAAADAGyXo0D19+nT59NNP5cMPP5SbN29K9uzZxcfHR0aOHBnfVQMAAAAA4I0SdOhOkyaNTJ06VaZOnRrfVQEAAAAAINoS9JhuAAAAAAASM0I3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgkhiFbn9/f/njjz+Mx2vXrpWmTZvK8OHD5dmzZ3arHAAAAAAAiVmMQrePj4+cPXtWREQuXLggbdq0kVSpUsny5ctl8ODBdq0gAAAAAACJVYxC99mzZ6VEiRIiIrJ8+XKpWrWqLFq0SObPny8rV660Z/0AAAAAAEi0YhS6VVXCwsJEROS3336TBg0aiIhIrly55Pbt2/arHQAAAAAAiViMQreXl5d89tln8vPPP8uuXbukYcOGIiJy8eJFcXFxsWsFAQAAAABIrGIUur/++mvx9/eX3r17y4gRIyRv3rwiIrJixQqpWLGiXSsIAAAAAEBilSwmLypevLjN7OVWX3zxhSRLFqNNAgAAAADw1olRS3eePHnkzp07kZYHBweLp6dnrCsFAAAAAMDbIEahOyAgQEJDQyMtDwkJkStXrsS6UgAAAAAAvA2i1Rd83bp1xv9v3bpV0qZNazwODQ0VX19fcXd3t1/tAAAAAABIxKIVups2bSoiIhaLRTp27GjzXPLkycXNzU2++uoru1VOROSff/6RIUOGyObNm+XJkyeSN29emTdvnnh5edm1HAAAAAAA7C1aodt6b253d3fx8/OTTJkymVIpq3v37kmlSpXE29tbNm/eLJkzZ5Zz585J+vTpTS0XAAAAAAB7iNFU4xcvXrR3PV5q0qRJkitXLpk3b56xjO7rAAAAAIDEIsb39/L19RVfX1+5efOm0QJuNXfu3FhXTCR8DHndunWlZcuWsmvXLsmRI4d8+OGH0r1791e+JiQkREJCQozHQUFBdqkLAAAAAADRFaPQPWbMGBk7dqx4eXlJtmzZxGKx2LteIiJy4cIFmTlzpgwcOFCGDx8ufn5+0rdvX0mRIkWkMeVWEydOlDFjxphSHyChcRu60ZTtBnzeMEGUBwAAACR2MQrds2bNkvnz50v79u3tXR8bYWFh4uXlJRMmTBARkZIlS8rJkydl1qxZrwzdw4YNk4EDBxqPg4KCJFeuXKbWEwAAAACAl4nRfbqfPXsmFStWtHddIsmWLZsUKlTIZlnBggXl8uXLr3yNg4ODODs72/wDAAAAACA+xCh0d+vWTRYtWmTvukRSqVIlOXPmjM2ys2fPiqurq+llAwAAAAAQWzHqXh4cHCyzZ8+W3377TYoVKybJkye3eX7KlCl2qdyAAQOkYsWKMmHCBGnVqpUcPnxYZs+eLbNnz7bL9gEAAAAAMFOMQveJEyekRIkSIiJy8uRJm+fsOalamTJlZPXq1TJs2DAZO3asuLu7y9SpU+X999+3WxkAAAAAAJglRqF7x44d9q7HKzVq1EgaNWoUZ+UBAAAAAGAvMRrTDQAAAAAA3ixGLd3e3t6v7Ua+ffv2GFcIAAAAAIC3RYxCt3U8t9Xz58/l2LFjcvLkyVfePxsAAAAAgP+aGIXur7/++qXLR48eLY8ePYpVhQAAAAAAeFvYdUx3u3btZO7cufbcJAAAAAAAiZZdQ/eBAwfE0dHRnpsEAAAAACDRilH38ubNm9s8VlW5du2aHDlyRD799FO7VAwAAAAAgMQuRqE7bdq0No+TJEki+fPnl7Fjx0qdOnXsUjEAAAAAABK7GIXuefPm2bseAAAAAAC8dWIUuq2OHj0qp0+fFhGRwoULS8mSJe1SKQAAAAAA3gYxCt03b96UNm3ayM6dOyVdunQiInL//n3x9vaWJUuWSObMme1ZRwAAAAAAEqUYzV7ep08fefjwoZw6dUru3r0rd+/elZMnT0pQUJD07dvX3nUEAAAAACBRilFL95YtW+S3336TggULGssKFSok3333HROpAQAAAADw/2LU0h0WFibJkyePtDx58uQSFhYW60oBAAAAAPA2iFHorlGjhvTr10+uXr1qLPvnn39kwIABUrNmTbtVDgAAAACAxCxGofvbb7+VoKAgcXNzEw8PD/Hw8BB3d3cJCgqS6dOn27uOAAAAAAAkSjEa050rVy7x9/eX3377Tf766y8RESlYsKDUqlXLrpUDAAAAACAxi1ZL9/bt26VQoUISFBQkFotFateuLX369JE+ffpImTJlpHDhwrJnzx6z6goAAAAAQKISrdA9depU6d69uzg7O0d6Lm3atOLj4yNTpkyxW+UAAAAAAEjMohW6jx8/LvXq1Xvl83Xq1JGjR4/GulIAAAAAALwNohW6b9y48dJbhVklS5ZMbt26FetKAQAAAADwNohW6M6RI4ecPHnylc+fOHFCsmXLFutKAQAAAADwNohW6G7QoIF8+umnEhwcHOm5p0+fyqhRo6RRo0Z2qxwAAAAAAIlZtG4Z9sknn8iqVavE09NTevfuLfnz5xcRkb/++ku+++47CQ0NlREjRphSUQAAAAAAEptohW4XFxfZv3+/fPDBBzJs2DBRVRERsVgsUrduXfnuu+/ExcXFlIoCAAAAAJDYRCt0i4i4urrKpk2b5N69e3L+/HlRVcmXL5+kT5/ejPoB+A9zG7rRtG0HfN4w3ssDAADA2y/aodsqffr0UqZMGXvWBQAAAACAt0q0JlIDAAAAAABRR+gGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMkqhC9+effy4Wi0X69+8f31UBAAAAAOCNEk3o9vPzk++//16KFSsW31UBAAAAACBKEkXofvTokbz//vsyZ84cSZ8+fXxXBwAAAACAKEkUobtXr17SsGFDqVWrVnxXBQAAAACAKEsW3xV4kyVLloi/v7/4+flFaf2QkBAJCQkxHgcFBZlVNQAAAAAAXitBh+7AwEDp16+fbNu2TRwdHaP0mokTJ8qYMWNMrhkAxJ7b0I2mbTvg84bxXp6ZZf5XywMAAIlPgu5efvToUbl586aUKlVKkiVLJsmSJZNdu3bJtGnTJFmyZBIaGhrpNcOGDZMHDx4Y/wIDA+Oh5gAAAAAAJPCW7po1a8off/xhs6xz585SoEABGTJkiCRNmjTSaxwcHMTBwSGuqggAAAAAwCsl6NCdJk0aKVKkiM0yJycnyZgxY6TlAAAAAAAkNAm6ezkAAAAAAIlZgm7pfpmdO3fGdxUAAAAAAIgSWroBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMki+8KAACAqHEbutG0bQd83jDeywMA4G1ESzcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYJIEHbonTpwoZcqUkTRp0kiWLFmkadOmcubMmfiuFgAAAAAAUZKgQ/euXbukV69ecvDgQdm2bZs8f/5c6tSpI48fP47vqgEAAAAA8EbJ4rsCr7Nlyxabx/Pnz5csWbLI0aNHpWrVqvFUKwAAAAAAoiZBt3T/24MHD0REJEOGDPFcEwAAAAAA3ixBt3RHFBYWJv3795dKlSpJkSJFXrleSEiIhISEGI+DgoLionoAAAAAAESSaEJ3r1695OTJk7J3797Xrjdx4kQZM2ZMHNUKAADYi9vQjaZtO+DzhnFaJuXFTZlve3lmlkl5cVPm216emWW+qrzEKFF0L+/du7ds2LBBduzYITlz5nztusOGDZMHDx4Y/wIDA+OolgAAAAAA2ErQLd2qKn369JHVq1fLzp07xd3d/Y2vcXBwEAcHhzioHQAAAAAAr5egQ3evXr1k0aJFsnbtWkmTJo1cv35dRETSpk0rKVOmjOfaAQAAAADwegm6e/nMmTPlwYMHUr16dcmWLZvxb+nSpfFdNQAAAAAA3ihBt3SranxXAQAAAACAGEvQLd0AAAAAACRmhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIkidH/33Xfi5uYmjo6OUq5cOTl8+HB8VwkAAAAAgDdK8KF76dKlMnDgQBk1apT4+/tL8eLFpW7dunLz5s34rhoAAAAAAK+V4EP3lClTpHv37tK5c2cpVKiQzJo1S1KlSiVz586N76oBAAAAAPBayeK7Aq/z7NkzOXr0qAwbNsxYliRJEqlVq5YcOHDgpa8JCQmRkJAQ4/GDBw9ERCQoKMjcytpBWMgTU7b7qvduVnmvKvNtL8/MMikvbsqkPPuWZ2aZlBc3Zb7t5ZlZJuXFTZlve3lmlkl5cVPm216emWUmhvxmraOqvnY9i75pjXh09epVyZEjh+zfv18qVKhgLB88eLDs2rVLDh06FOk1o0ePljFjxsRlNQEAAAAA/1GBgYGSM2fOVz6foFu6Y2LYsGEycOBA43FYWJjcvXtXMmbMKBaLJR5rZj9BQUGSK1cuCQwMFGdnZ8pLhGVSHuUl9DIpj/ISepmUR3kJubz4KJPyKC+hlxkf79FsqioPHz6U7Nmzv3a9BB26M2XKJEmTJpUbN27YLL9x44ZkzZr1pa9xcHAQBwcHm2Xp0qUzq4rxytnZOU4/sG97efFRJuVRXkIvk/IoL6GXSXmUl5DLi48yKY/yEnqZ8fEezZQ2bdo3rpOgJ1JLkSKFlC5dWnx9fY1lYWFh4uvra9PdHAAAAACAhChBt3SLiAwcOFA6duwoXl5eUrZsWZk6dao8fvxYOnfuHN9VAwAAAADgtRJ86G7durXcunVLRo4cKdevX5cSJUrIli1bxMXFJb6rFm8cHBxk1KhRkbrRU17iKZPyKC+hl0l5lJfQy6Q8ykvI5cVHmZRHeQm9zPh4jwlFgp69HAAAAACAxCxBj+kGAAAAACAxI3QDAAAAAGASQjcAAAAAACYhdAP/Yp3mgOkOkFBs2rRJnj9/Ht/VAAAAQAwQuoF/OXz4sIiIWCwWgjfi3ccffywDBw6UW7duxXdVAAAAEAOEbiCC/fv3S4UKFWTSpEkiQvBG/Dpx4oT88ssvMm3aNMmePbvcvHkzXj+PYWFhL/1/xAzHloRt6dKl8tdff8V3Nf5T+E4gMbF+Xl+8eGGX7R05csQu20HCROgGIsiTJ4+MHTtWJk2aJJMnTxYR84N3XHRn50QmboSGhtp1e6oqGTNmFFWVBQsWSNeuXeXmzZt2LeN1rMH68ePHEhoaKkmSJJGDBw+KiEiSJIn/58P6vQgMDJSQkBBTy4p4kcJa7sOHD00tEzF35coV+fbbb8XJySm+q/KfYP1O3L59O87L9vX1tfs2VdX4zsfX7691SJK9f5fwPxaLRdatWyejRo2SZ8+exWpbBw8elLJly8o333xjp9rFXsTPrr0/x2b/5iZEif+sCW+VM2fOyJEjR2Tv3r3xUn7WrFllwIABMmLECJk4caLMmDFDRMwJ3tbtPXr0SEJDQ+Xx48ciYt8WRGsZFovlpcvNZC0jKCjI9LISgl9//VUGDhwo9+/ft9s2ixcvLsWKFZOePXtK586dpWHDhuLi4hJnJ3FJkiSRS5cuSZs2beTo0aOydOlSqVixouzatStOyhcx97NqsVhk2bJlUqlSJblw4YKprfdJkiSRc+fOyW+//SYWi0VWrFghzZo1s+vnxR7+fYIem/1/+/ZtuXfvnty4ccMu23sV6zbv3bsn165dk7CwsFj/LXPmzCm//vqr5MqVS06ePCmnTp2yR1UTjZf9ncz8flgsFlm8eLFky5ZNAgMDTSvn306ePCm1a9eWDRs2xGo71n1jDRIWi0UuXLhg/H9cunLlity9e1eSJ08uGzZskEWLFtmtJdYerJ+tixcvyqVLl+Ty5ct237ZI3PTGOn78uPj4+Ej+/PljfSG6RIkSMmHCBBk0aJBMnz7dTjWMnYi/B/Y8D96xY4dMmDBB/v77b7tsL7EgdCPBWLNmjdSrV086dOggderUka5du8q1a9firHzrAfr48ePy8OFDSZ06tfTu3VumTZsmIvY94KiqWCwW2bRpk3To0EEqVaok7du3l23bttmtBdFaxoEDB2TChAnyxRdfyMqVK0XE/JMAa9lbt26VwYMHy4EDB0wrR0Tk7t278dJCYrVy5Upp3bq1iIjdTiCsn8d3331XLl26JNmzZ5f8+fNLSEhInJ7EOTg4SEBAgHTr1k3at28vc+fOlWrVqplycej06dNy8OBB+e233yQ4OFhEzPmsWssLDg6WTZs2ycCBA6VgwYKmt95Pnz5d6tSpI5988om0atVKOnXqJOnSpTO1zOjYvn27DBgwQD755BOjR0NMj3vr1q2Tli1bSoUKFaRNmzY2Q3bsyXqsWbt2rdSrV08qVqwo3t7eMm7cOLl7926stp0yZUoJCgqSdu3aycSJE+XPP/+0U61jzvq3OH/+vJw6dcr4O9m7DIvFInv37pWpU6fKzz//LDdv3pQkSZLYPchEbOH29fWVKVOmSK5cuexaxuu4uLhIvXr1xN/fX0Ri3iqcJEkS+fvvv+Xjjz+WGzduyIoVK8TT0zPOhycEBQVJ9+7dpXXr1jJv3jx55513JGXKlJIsWbI4rcfrWCwWWblypVSpUkW8vb2lUaNGxrlJTM+xrK97/PixPH36VETM7431559/yrZt26RNmzbSoUOHGB/b5s+fL5cvXxZHR0cZMGCAfPbZZ9KvX794D96+vr7SvXt3adWqlfTs2VOePXtml+P3ypUr5Z133pHkyZMbvb3+M70xFUgAtm7dqunSpdPvv/9eQ0JCdPPmzWqxWLRNmzYaGBgYZ/VYs2aNpkqVSseOHavjxo3TRo0aqZOTk06ePNlYJywszC5lrV27Vh0dHXXixIm6aNEiff/999ViseiZM2fssn1V1ZUrV2rq1Km1Vq1aWqpUKXVwcNBu3brpixcvVNV+78Uq4vZWrFihqVKl0okTJ+rx48dNKU9VddWqVVq+fHl1dXXVjz/+WP39/e1exuv4+/trhgwZ9IcffrBZ/ujRI7u836VLl+pPP/2kjRo10rx58+r69es1JCQk1tuNitDQUFVVXbJkiSZNmlTz58+ve/bsMZbb4/1Zt7Fy5UrNmTOnli9fXtOnT6/vvPOOrly5Mtbbf5Vdu3ZpiRIltG7dunrs2DHTyvm3SpUqaYoUKfSjjz6KszKjYuvWrZo0aVJt0aKFZsmSRatWrarTpk0zno/O33rjxo3q6Oio33zzje7du1dHjRqlFotFd+7caUbVdevWrZoqVSr94osvNDAwUHv27KnOzs66Zs0au2zfz89Py5Ytq926ddOTJ0/aZZsxYf0brFq1Sj08PLREiRLq7OysrVu31n379tm1rHXr1mnq1Km1aNGi6unpqV5eXnrhwgVV/d9xwV78/Py0SpUqWqVKFT1z5ozdt/8m06dP19SpU+vly5dj9PolS5bomTNn1NfXV52dnbVmzZrq4OCgCxYsUFVzfvde5cWLF7p69Wr19PTU5MmT63fffaeqqs+fP4+zOryKdT9cvXpVc+TIobNnz9alS5dq3759NUmSJPrLL7/YrBfd7W7YsEFr1qyppUqV0kqVKummTZv0wYMH9n0T/1/eo0ePtECBAmqxWLRJkyaR6hJVQUFB6uLioiVLljTOdZ8+faqTJk1Si8VicwyOS6tXr1YnJycdMGCATp06VV1dXbV48eJ68+bNWG330KFDmilTpkjnS7dv347VdhMLQjeixYwfjwcPHmiPHj10zJgxqqp64cIF9fDw0BYtWmi6dOm0SZMmeunSJbuX+2+PHz/WBg0a6Mcff2wsCwwM1NGjR2uqVKn0m2++MZbHdj88evRIGzRooF988YWqqv7zzz/q6uqqPXr0iNV2I7pw4YLmzJlTp0+frqrhB/dNmzZp+vTp7VqOddsRHT9+XHPkyKE//vijzfK///7b+P+Y7sOIr/Pz89PMmTPrp59+quPHj1dXV1dt1qyZbt++PUbbjoklS5aot7e3qqreuXNHFy1apA0aNND8+fPr559/Hu0ffev7O378uG7evNkmeDZp0kQ9PDziNHirhoeoBQsWaIUKFbRq1aq6ZcsWo54R/x4xPVnet2+fpk+fXufMmaOqqtu3b1eLxaLff/997Cv/CocPH9ZChQpp0qRJ9ciRI6qqxsUoe4u4j8qXL6+lSpXSNGnS6KZNm0wpL7oCAwN1wIABOnPmTFVVvXHjhnbq1EkrVaqkU6dONdaLynf22bNn2rFjRx03bpyqhh/b3Nzc9IMPPrB7vUNDQzUkJETff/99HTp0qKqGfwdz586tvXr1MtazR+Dw9/fXUqVKxXvw3rVrlzo7OxsnrVu3blWLxaILFy60azn9+vXTefPmaWhoqPr6+mq9evXUzc3NOIbbMxj/9NNPWrp0aXV2djaCh5kh8eTJkzbhITg4WKtXr66ffvqpvnjxIlq/TYGBgVqpUiXjHGXChAlqsVi0UqVKevHiRWO9uAje1jLOnj2rOXPmVDc3N23SpIkRaMw6vkWHr6+vTp06VQcNGmQsu337tg4dOlQtFkuMg/eGDRuMBpOjR49qnTp1NGvWrHro0CG71j9ivU6fPq1lypTRPHny6ObNm1+6TlRcvnxZixQpomXKlEkQwfvmzZtaunRp/eqrr1Q1/BieM2dO9fHxsVkvJp/pWbNmacWKFVU1/Jx7xYoV2qRJEy1YsGC8XWCIS4TuRM565TmuXL9+3e7bDAkJ0WXLlun58+f1zp07WrJkSe3atauqqi5evFgtFos2aNBAr1y5YveyI3ry5IkWLlxYBwwYYLP88uXLWqtWLbVYLPr555/bpay7d++qm5ubHjx4UG/evKk5cuSwCcI//fSTTUCNrrCwMD127JjmyZMn0nbWr1+vqVKlstsJf//+/bVfv342P+jr16/XwoULq2r4Sfi8efO0Zs2amj17du3QoUOMylmyZImePn3aeHz+/Hn94osvjJN71fAQXrp0aW3atKnu2LEjZm8omjZu3KgWi0UnT56sFStW1MaNG+sHH3yggwYN0jRp0uiJEyeivc3ly5drhgwZtESJEpokSRL18vLSn376SVXDg3fevHl148aNpgXvV/2YXr16VcuWLatVqlTRrVu3GuutWLEiVuV9/fXX2rRpU1UNP2HMmzevdu/e3Xj+zp07sdr+yzx//lyPHDmi+fPn17Jly2pwcLCq2r8Vz8rf31+vXbtmPO7UqdNLg/eNGzdMKf9Vjhw5og0aNNCSJUvqnj17jOXXrl3Tzp07a8WKFaN1MhQcHKzFixfXX375RW/dumUc26yflfnz5+uuXbvs+h6aNGmi69ev12vXrmn27NltjqXr1q3T3bt326WciMH71KlTdtlmdH322Wfavn17VQ3/ruTLl0+7detmPB/TsGr9+/zzzz96/fp1fffdd22OoUeOHNG6deuqm5ub3Vu8nz9/rsuXL1cPDw+tXLmyqSFx27ZtmjRpUq1Xr55+++23+uTJE1VVHTdunJYqVcpYLzqBwrqNkydPaocOHXTSpEnq6uqqHTt2tDn+R9ymmSH8zp07eurUKV2xYoVWqFBBGzRoEGmfxuVFW6snT55o165d1WKxaO3atW2eswbv5MmTR2oFfZ2wsDB98uSJNmjQQEeNGmVsy8PDw64X+qx/r/v372tISIjevXtXVcODd5EiRbR+/fo2x5no/n0DAwO1QIECNsE7ODg4XoL3rVu31MPDQx8+fGj0SogYuNeuXRvjba9atUrd3Nx06NChWqNGDW3cuLG2bt1ax44dqxaLJc57KsY1Qncitn37dk2VKlWsvgDRERAQoEmTJtWff/7Z7tt++vSpqqr+/PPPWqFCBeOgs3jxYq1evbq6urrGSWv3oEGDtH79+nr27Fmb5UOGDFE3Nzd1d3fX27dvx/oH88WLF9q2bVv9/PPPNXfu3Orj42P8GN64cUPbt2+vixYtinI5ly9f1uXLl6tq+D7r3r27nj17Vh0dHXX16tU26968eVM9PT2NVsXY2rZtm3GgtAaX/fv3a4ECBbRt27ZaunRpfeedd/SDDz7QZcuWqcVi0VWrVkWrjMDAQK1cubLR/e/u3buaI0cOTZkypfbp08dm3UOHDmmpUqW0RYsWunXrVju8wzebOHGiFi9eXHv37q1Hjx41lpcsWTLaJ/z+/v5G96u7d+/q9evXtWPHjlqhQgWjNatBgwaaOXNm3bJli13fh+r/ThZ27NihY8aM0fbt2+vu3buNwHj16lUtV66cVq9eXb/77jv95JNP1GKxxOoC4KBBg7R///6qqpFC2rJly/THH3+MVZiwbisgIEBPnjypFy5cMJYdPXpU3d3dtXLlyvrs2TNVtW/wDgsL0wcPHmimTJm0Xr16+scffxjPderUSZ2dnXXjxo367Nkz/fzzz7VOnTr69OnTOOuSevbsWfX29taUKVPaDKNRDT8Wde/eXQsVKmS0gkfFgAEDtH///porVy6bv+X9+/e1S5cuOm3aNLsEKuvfqXHjxtq4cWPNkyeP9uzZ0/isPHjwQFu3bq3ffPON3f6m/v7+WrZsWW3Tpo3NRUCz/LsnSdu2bXX48OEaFhYW6bsyd+5cXbp0aYzLWrVqlWbLlk3LlCmj6dOn140bN9o8f+TIEW3YsKE6OzvbtOLG5P38+eefeuDAAZtj2MqVK7V8+fLasGFDI9SYEbzXrFmj48eP1zRp0mitWrV09OjReuHCBc2aNatNz47ouH//vpYrV07bt2+vwcHBumfPHs2VK5d27NjRpmfE4cOH7fU2DNZ9eunSJQ0ICNDz58+ravjnZcmSJVq+fHlt1KiRcfFy+vTp+ssvv8Rpt3erP/74Qz/88ENNkiRJpN/nO3fuaJ8+fTRdunT64MGDKNcvODhYy5Ytq8ePH9fbt29rtmzZbC68rVixIlYXM6312Lhxo9atW1fLly+v5cuX119//VVVw4N34cKFtUGDBjYXLqMrMDBQ8+fPr15eXpGCd4oUKXTSpEkx3nZUrF+/Xr/++mt99OiRVqxYUWfMmKGurq7q4+Nj/DZeunRJGzdurNu2bYvydv/66y/18/PTQ4cO6b1793TYsGFarlw57dmzpx44cEBVw3+by5YtG6+9iOICoTsRu3Llivbo0SNSQDRLUFCQdu3aVfv162daGWPHjtUiRYoYP7hDhw7V6dOnG194e7EeRG/evGnTer9mzRotWLCgDhkyxGZsdd++fXXy5Ml6//79aJUTsatacHCwTXAYOHCgWiwWbdiwoRFWVcPfc4ECBaJ8keHZs2fapk0brVixog4YMMDolhsaGqqtW7fWRo0a2Yz3Cw0N1QoVKkTrJPpVIp7Ibtq0SXv06KG3bt3SkJAQ/e6777Rly5Y6aNAgI2gEBQVppUqVYtQKbW1NOHHihN69e1cPHDiguXPn1sqVK+vvv/9us66fn5+6u7vr+++/r48fP47x+3uZ3bt36/jx47V///66Y8cOo1737t2zWW/YsGGaL18+m9bNqFi4cKEWKlTI5qTj+vXr+v7772v58uWN9Zo1a2acXNnbqlWrNE2aNPree+9prVq1tHDhwjp8+HAjWF+7dk3r16+v5cqV0wIFCkT56nRYWJhxEn3nzh3jb7Np0yZNnTq1pkmTRvv372/zuerWrZt26tTJ2M9RZR3yEHHMuKurq3p4eGiKFCm0Y8eOxhhja/CuXr263Y81VgcPHtQcOXJoixYtbIJ3t27d1GKxaNWqVTVVqlQ2F23iysWLF7Vhw4ZaqVIlXbx4sc1z165d0969e782ZN2/f9/mezZ79mxNnjy5VqxY0ejG++LFCx0+fPhLe99ERWhoqPG5uHHjhj5+/FgfPXqkqqq///675sqVSz09PW1eM2LECM2TJ4/dvyeHDx/WatWq6dWrV+263VfZtm2b8Zn56aef1MPDQzNkyKC9e/e2+a506dJFfXx8bH5PXifiBSlrl+QpU6bo9OnTtXbt2popU6ZIFxYOHjyo7777rp47dy7a7+NV8zc0bNjQ6PGxcOFCrVixor7zzjt2Hed55syZSL2OAgICdOLEiVqmTBl1dXXVzJkza7169fTJkycxCqSHDx9WLy8v7dKli969e1f37t2ruXPn1o4dO+qvv/5qtObdunXLboE34j719PRUd3d3TZs2rX7wwQfGOcSSJUu0cuXKWqhQIfXx8VGLxWJzDDKLtW4hISFGw4pqeCNB+/btNW3atJGC9927d2MUkGvUqKGdO3fWPHny6AcffGC05N+9e1cbNGigc+fOjcU7CQ+kjo6OOmnSJN28ebO2bdtWLRaLce5x+vRpLV68uFaqVEn379//xu1Z9401kFovzgcGBmrhwoUjBe9Ro0ZphgwZjHNje/Pz89OMGTPq/Pnz9cGDB9q+fXtNnTq1zXh11fAGqFKlSuk///wTpe2uXr1a3dzctECBAurg4KD9+vXTM2fORBqS+Mknn2iBAgVM6U2bkBC6E7m4nhzjjz/+0Hr16pl2Yurv768ODg5aqVIlrVmzpjo7OxuTcNnbqlWr1NPTU/Pnz6/e3t4aEBCgquEnjIUKFVJvb2/t2rWrtm3bVtOnTx+tixv/7j65fv16rVu3rjZs2FAnTpxoLG/ZsqVmy5ZNBwwYoOPHj9cuXbpo2rRpI4XIN7l3756WK1dOLRaLTZeq9evXq7e3t9atW1cXLlyoR48e1Y8//lgzZswYq+7rL7Nhwwa1WCzq4+NjHFD/3bo0cuRIdXNzi/GENQ8ePNCiRYvqe++9p3fu3NEDBw5orly5tFOnTpFOqI4ePWr34RcrV640wmi5cuW0UqVKOnjwYJsfkPXr12uXLl00U6ZMMeoqtXjxYvXw8DDCuvU7fvHiRbVYLKaPAz548KDmypXLGI//8OFDdXBwUA8PDx04cKDxPXn48KFevnw5SifGGzdutJmsbNWqVVqpUiXNly+fjhw5Un19fXXo0KGaJUsW4yTs7t27Onz4cM2SJUu0WxS7d++uXbp0Mfbd7t271cnJSadPn66nT5/WZcuWafXq1bVBgwbGyc7Ro0c1ffr0Wr9+/WiV9TIRTzYjPvbz81MXFxd99913ba7oz58/X6dNmxZnF1CvXLmif/zxh96+fdu4mHHmzBmtX7++1qhRI1Lwfl0r8Zo1a7REiRJavnx5bd26tbF84sSJ6uTkpK1atdJOnToZx9HoHtuWL19ucyFi1apVWrp0ac2fP7/27t1bDx48qKqqc+bMUUdHR61Vq5Z27NhR27Rpo+nTpzetu2LEEGGmZ8+eaePGjY0eEGfPntXmzZtrnjx5dO/evaoafoFp+PDhmi1bNv3rr7/euM1/n/Du3LlTFyxYYDOfyeXLl7Vhw4aaOXPmSN+/qIb6l3nV/A0zZsxQ1fDP2tKlS7VgwYLaqlUru/RQGDp0qGbPnl1dXFy0QoUKeubMmUiTic6cOVM7duyoyZIli9Ux1t/fX0uUKGEE7/3792uRIkW0cOHC6urqqn5+frF+P/+2c+dOTZkypc6cOVN37Nihq1at0kyZMmmzZs30ypUrGhoaqlu3btUePXroO++8E6eBe+PGjdq4cWMtU6aMtm7dWnfu3KkvXrzQf/75Rzt16qTp06ePVqupdbsPHz60+Q4uWLBAc+TIoWXKlLFZf/jw4Zo/f/4Y98xQDf+8N2nSRD/77DNVDf9u5MmTx2hNt35Gjx8/rhUqVHjj+Y31PVgDacGCBTVlypTaqVMnvXr1ql6+fNkI3tZhlcHBwaZNNnb27FmdNGmSDhkyxFhmvYhQo0YN/fLLL3XlypXas2dPTZs2bZQnHv33BMmbNm1Si8WirVu3Ni6E7ty5U3v06KEZMmSI9m9DYkToRrTZu+Xw3/bv36/t2rXTXr162b2rifVgd+zYMc2SJYt+9tlnOnfuXPXy8lJ3d3fj5G7r1q06atQorVy5sr733nvRmt342LFjarFYdPjw4aoa3k03ZcqU2qNHD+3QoYM6ODhox44djfWHDh2qjRs31tKlS2uXLl1i9J6fPXumNWrU0BIlSmjt2rWN8b+q4WG4Q4cO6ujoqAUKFIhWy+SrRGyxvH37tnESt3PnTk2aNKl269bNpoV3/fr12r179xgH0Yj8/PwitSZYg7eZJxP79+/XnDlzGuPNAgIC1MnJST09PbVPnz768OFDff78uc6ZM0ebN28e4zGf58+fVwcHB/3kk09slgcEBGjRokWNkGGWVatWGb1ZLly4oO7u7tqzZ08dNWqUOjk56aBBg6LVcnj9+nV1d3fXzp076/nz5/X06dOaLl06HTdunPbr109Lly6trVu31smTJ+uHH36oyZMn1+LFi2u5cuU0d+7c0f68LF68WDNnzmzzAz5+/PhIYwh37typlSpVMsaqvXjxQn///fcYteC9jPUk19oaaj32HDlyRNOmTavNmjWzOa7EVVfP1atXa6FChTR79uxaqlQpHT58uFHHv/76S+vXr6916tTR+fPnv3Fbfn5+mjp1av3kk0901KhR6u7uriVLljRODufPn699+/bV2rVr67Bhw6J98eTPP//UUqVKaaNGjfSvv/7SS5cuabp06XTy5Mk6ZMgQrV27tlapUsXoyePn56etW7fW9957T4cMGRKlAJoY/PDDD1qqVCnje7du3Tpt0KCBpk+fXitUqKBVqlTR7NmzR+m78rI5OJo1a6YWi0WrV69u8/seGBioDRo00OzZs9vtt/hN8zc8fvxYQ0NDdfny5bEKSlarVq1Sd3d3XbNmjW7atEkrVKigHh4eevjw4UjfuSdPnqiPj4++++67MW7tVrUN3rdv39Zbt27p0aNHTZuXZvjw4dqgQQObZb///rtmyJDBGLZjFZsLJtG1fv16TZ48ufbr108nTJigXl5eWqpUKZ09e7aGhoZqQECAdu/eXS0WS7R6v61du1br16+vpUqV0lmzZum1a9f00aNH2q9fP/X09DTGCLdr1y7ajRgTJkzQYcOGGY+tw4Py5Mmj+/fvN4a2Rey+PmfOHOOzGtWx8q8LpIGBgXr58mUtUaKEenh4RLlVObrCwsL0zp07mitXLnVwcNDOnTvbPH/s2DHt0KGD5s2bV4sXL67169eP8hw1UZkgec+ePTp69Ght06ZNnFwISggI3UiQQkNDTTsJPXLkiK5Zs0Y//fRTY9mzZ8+0SpUq6urqatOq8uzZs2i36gcHB+vs2bPV0dFRR48erevWrTNmgXz+/Llu2bJFnZ2dtV27dsZrnj9/rsHBwbEavxYcHKzXrl3Thg0bqre3t03wVg1vKb148WKsrpa+qsUyb968+sknn+jt27f1wIEDmjRpUu3Ro4deu3ZNX7x4oTNnztQePXron3/+GeOyI/p3a8LevXs1T548+u6775oywVFwcLCuW7dOu3TpoqrhPyB58uTRTp066eDBgzVTpkw6ePBgffjwoaqq8d+Y+uWXXzRFihQ6dOhQPXfunN64cUNHjBihuXLlMu0H2Orq1at65swZDQkJ0fr16xvvWVXVw8NDs2XLpiNGjIhWL5ujR4+ql5eX9u7dW8eNG2cz+d26deu0du3a2qpVK127dq3u3bvXuI1eTOZxmDx5shYoUEBVw1thv/76a50wYYJWqFBBQ0JCbI4rCxYs0JQpU5rSTdja8+ODDz4wLkBZW0SWLVumKVKk0ObNm8fpGLbNmzdrmjRpdMqUKXr37l0dPHiwZsuWTTt37mx0ZTxz5oxWrFhRmzRpEqlFNKJjx46pr6+vTpgwwVh27tw5LVKkiJYoUcJm8rvYHMsXLVqktWvX1hYtWuiECRNsjtu+vr7atGlTrVixYqST9vgYr2oPr6p3kSJF9P333zcenzlzRpcuXaoff/yxzp07N8q9eiLOwWENCM+ePdMePXqok5OT+vr62qxvnU8jX758dunh9qb5G2bPnh3rMqwWL16s3333nc0kVNbf+jx58ry01XnmzJlapkyZWPci9Pf3Vy8vL23durVdbwP6b2FhYdq5c2etU6eOqv5vRn/V8DlysmTJopcvX7brbR5f5t/f96CgIPX29taRI0cay58/f64dO3bUkiVLGhePT506pb17947yBbJ9+/ZpmjRpdODAgdqxY0d1cXHRHj16aEBAgD548EAXLFigVatW1Ro1amjXrl2jdT4QGhqqX331lVosFh0/frzNcx06dNCPPvpIc+bMaTNvxL1797Rly5bGhYSo7N/XBdK0adPqO++8owEBARoQEKAVKlQwZcLkiPX09fVVDw8PLV68eKSu8SEhIfrw4UMNCgqK1hCvqEyQ3Lp1a/Xz8zPltm4JFaEb/ynBwcHq6empFovFJvSq/u/H2NPTU/fv3x+tH6eXdYGbNWuWOjo6aubMmXXKlCk2z23ZskXTpEljE2js5e+//9aGDRtqzZo1jfuEDh06VHv27Bmr7b6pxbJEiRLG7d2swdvHx0fv37+voaGhdu8hETF437t3T3fs2KFFihSxeyg9cuSI9urVS69cuaJnzpzR4OBgrVWrlnbq1ElVw39c3Nzc1MXFRT/66CO73bt68eLFmiZNGs2dO7d6enpqzpw57Tre93XzDaiGT5hSuHBhXb9+vaqGj+1t2bKlDh061OhiHh1Hjx7VsmXLqqurq003NtXwlgtvb29t3rx5rN/j4cOHNX/+/FqjRg21WCy6Zs0aXbp0qSZLlizSfaL379+vBQsWjPFwB6t/9/ywzv1w8OBBTZo0qXbv3t2m58fq1auN7vVm35XB6ubNm1q3bl0jJN+6dUtz586tFSpU0KJFi2rnzp2Niw/nzp177T65d++eZsuWTS0Wiw4cONDmOWvwLlu2bKwmL4r4eVy2bJnWrl1bc+fOHWlOEWvwtt7Kziqxhm7V8MkgT5w4YdN9duXKlVqiRAmjS3lM/HsOju7duxvHyxcvXui7776rmTJlijQZ1D///BPt70hs5m+wx29FUFCQ8RkdPHiwUSfV8N/6qlWrar58+SLd33zcuHGaK1cuu4ydNWPsv/U9RNynq1atUgcHB6ObtnWfrl69WgsWLGjK3R8i+uKLL3TQoEE2F2WePXumZcqUMSb/sl4ICA0NNY43EdeNisDAQP3ss8/0yy+/NJYtXrxYCxYsqN26dYs0PCc6QxOsf+9nz57prFmzNGnSpDYXh8eNG6fp06fXGjVq2Hwvhw0bpp6entH6TXxdIF20aJFaLBatX7++XrlyxbQhpI8fP9awsDDjvWzfvl3d3Ny0bdu2Nj0DYjO843UTJFerVk1z584d69/exIbQjf+cS5cuGa2z1u561h+y58+fa9GiRbVkyZLRHrN3+fJlXbZsmaqqLl26VNu2bas//vijpk2b1uaWLla//vqrWiwWm/vJ2suFCxe0WbNmxr0fnZ2d7dIt+XUtlhs2bNDq1atr48aN9dKlS3rw4EG1WCzat29fU2/D5OXlpa1atdL79+9He7KtqPj666+1aNGixg/RqVOntECBAsa4/cuXL2uTJk30008/tfsPSEBAgG7ZskU3btxo/GDF1uvmG4g4O+rJkye1QIEC+uWXX+r58+d19OjRWqVKlVhdlT5+/Li6u7trpUqVIrXwbty4UUuUKGFMfheb0PThhx+qxWKxmXiubdu2mjFjRvX19TVC8ccff6xFihSJ8Unpv3t+rFy5UsuVK6fu7u7GDK8nTpwwen5Yu9B9+umnOn36dFM+r68SFhamS5Ys0VOnTunNmze1QIECRtf6Hj16qLOzszZv3jzKn7MdO3ZoyZIltWzZssaJofVvdv78ec2ePbt6e3vH+Ltv3dapU6f07t27um7dOi1durR6enpG6uK4Y8cOrVGjhtatWzdO96kZgoODNX/+/FqsWDFt0qSJnj59Wp8/f663bt3SYsWK6ejRo1U19jPsR+yJYQ2FL1680ObNm2umTJliHO7jev6G17l8+bKWL19eCxUqZLQWRvytL1CggLZs2dJY//r16+rj42PXeQDMGPsf8aLdyJEjdfPmzdqvXz8tUKCAMaO2avjF9tKlS5s2+ZbVd999Z7RUW79/z54904oVK9rM82AN3h999JHWr18/ysf4sLAwvXjxoubIkUNdXFxs5sVRDQ9x+fPn1549e9r0Xojq9ufOnatZs2Y1QvuzZ890xowZmjRpUqM1WjW8tbtgwYLarl07HT16tLZr107TpUsXo7HI8XnHns2bN2uzZs2MY6b1O7djxw51c3PT999/P1pDKt8kriZITgwI3XirvW6GSGsgtQaliD/G0W3JiziDeP/+/dVisei8efM0LCxMf/zxR02ePHmkMbqq4a00Zo07vHLliv744486ZswYu5bxuhbL9evXa7Vq1bRp06Z68eJF9fPzs1uX8lc5fPiwVq1a1e5dhCOevFetWlWrVq2qquFB2NPTUydOnKi3bt3SUaNGae3atU0/sbGHqMw3YL3irqrau3dvzZ07t+bOnVtdXFzs0tJ+/PhxLVGihPbo0SNS8N66dWuMWtEjevLkidaoUUO7deumhQoV0vfee09VwwNF+/bt1cHBQYsUKaIVKlTQDBkyxPgEO2LPj7///ltPnTqladKk0c8++0w///xz7dmzpyZNmlQXLlyof/zxh2bNmlXz5s2rJUqU0HTp0tn1pCaqrC1jX331ldavX9+42DBjxgwtVKiQtmzZ8rU9RY4fP66bN2/WtWvX6o0bN3T37t2aN29eo2ur6v+OoxcuXIjxZI0RJxpycXHR0aNH64sXL3TlypXG8eXf+2/37t12uzAV3x4+fKgLFy7URo0aGRdt9+3bpytXrtT06dNH+3j+pjk4unfvbhO8W7VqpRaLxbidT1TF9fwNL7Nt2zZdvXq1cSvV1/3Wv3jxItKQrriaIC+mjh49qmnTptWxY8ca+7RNmzY6ZcoUHTBggCZPnlzLlSunlStX1nTp0sXpfY/37Nlj01Xc19dXHRwcbIaEqKq2bt1a27dvH6ULRxGD89SpU9XZ2VlbtmwZKZAuXbpUXVxctH///tG+B/mNGze0RIkSWqxYMWNOj4jBO2IX+QkTJmiLFi2M+UBiO5wtrgPp2rVrNWXKlDpmzBhdsmSJent7a+rUqY33vX37ds2XL5++8847UR6//SZxOUFyQkfoxlsrqjNElilTxjhZi03r2qtmEH/69Kn+8MMPmixZspcG78ToTS2WxYsX1zZt2sTZ7Pr2PlHasmWLtmvXzmiJuXTpkubNm1fHjx+vYWFh2rt3b/Xw8NBcuXLZLYzGhajON9ChQwfjNb/99ptdwnBE/v7+WqpUKe3WrZspY/Ct4fLHH3/U/Pnz2wwlWb58uU6bNk2nTp0a61tJWXt+9OrVS0eMGGEz+/ODBw902rRpmjx5cvX19dW///5bp0+frhMmTDB1jGdEx44d0+3bt0cap2e97UvEFv/PP//8tS3+y5cv14wZM2qJEiXUYrFo5cqVderUqbp792718PDQunXrGuvao2v3hg0bNGXKlDpnzhybML169WqtVauWNmnS5K04cYt4W8A7d+5ECoY///yzdunSRR0cHLR69epqsVj0q6++ilJgic4cHP8O3h06dIjR5zQu52/4t6FDh2qOHDm0ZMmS6ujoqB07djQmpSpcuLCWLVv2pRdmzLgXuBnOnz+v48aNM2bRVg3fp7Vq1dKWLVvq2rVrdefOnTpkyBCdNGmSaXdDiPjZixgO58yZox4eHjpgwACjZ8F3332nDg4O2rRpUx0yZIh269ZNnZyc3jhxVsQLIxFNnTpVs2XLpp988kmknmUrV66M9jHd+l7u3bun5cuX1yJFiry0xTti8FYN/720Rw++uAqk1nH2NWrU0M8//1xVwy9Iubu7G5PCWff5pk2btHjx4nYdqmfmBMmJCaEbb7WozhCZN2/eWI+t/PcM4r/88ovx3JMnT/SHH37QlClT6oABA2L7thIEs1ss40tYWJgxo2qGDBl01KhReuHCBR0/fry+++67ev78eX38+LH+9ttvunLlSrvMsGummM43YB2zbhZ/f38tW7astmnTxq5dSiN6+PChzp07V/Pnz2+0eNtbxJ4f/x4qcv/+fe3UqZO2adPGlLJfZ/Xq1ZoqVSrNnz+/JkuWTEeNGmWcIM+ZM0fLlCmj77zzjrZt21adnJxeG7D8/f01U6ZM+sMPP+jdu3f12rVr2qFDB/X29tbp06fr7t271dXVVStVqmSXuj99+lRbtmxp9Mh4/Pixnj17VidPnqxbt27ViRMnauPGjdXb2ztRn8BZT3LXrVun5cuX1wIFCmjp0qVtfjtUw/fHkSNH9J133tGCBQtGKQzHZA6Onj172mWOgbiavyGiSZMmabZs2fTQoUOqqjp9+nS1WCzGkInAwEAtVqyYurm5xWqugfjy4MED9fLy0ixZsujQoUNtnlu3bp2xT+PqtksBAQH66NEjVQ0/1li7YX/zzTdaokQJ7dOnj3GBY/fu3Vq3bl2tXbu2Nm/e/I0tqNbvha+vr3br1k3btGmjH374ofH8119/rTly5NBPPvkk1r1brL+PJ0+e1NWrV6vFYtEqVaq8tMU74gUke4qLQBoSEqLPnz/X3Llz69mzZ/XWrVuRZmFfsGCB3rt3T1XNuUuRmRMkJxaEbry14mOGyH/PIP7zzz/bPD9lyhR1cXHRmzdvxrqshMDsFsv4cujQIX3vvfd0/Pjx6uXlpT179tRu3bppwYIFbSZxSSwS0nwDEZkx0dC/PXr0SOfOnatFihTRxo0bm1LG8ePH1c3NTQsUKBDppHf48OFavHjxOBu/FhYWpo8ePdKaNWvqjz/+qGfPntWffvpJU6RIoX369FHV8JOfCRMmaKtWrbRRo0ZvPAleuHChFipUSB88eGCcNF27dk3btm1r3GZq+/btWqBAAbvMa/DkyRP18vLSPn366J07d7R3795arVo1zZYtm+bMmVO/+uornT9/vjZq1CjRdylfv369Ojk56VdffaXbt2/XgQMHqsViMW5NqPq/1r6HDx8avROiIiZzcPz7dmIxFVfzN6iGT/TWsWNHXbJkiaqq0Q3/008/1bRp02rz5s2Nu3e0a9cu0bRs/5u/v796enrGyT59nadPn2r58uW1YMGC+tNPP6nFYrG5UDR16lQjeFuHmFj3eVRvWbZ69WpNnTq19u3bV7/44gvjFofWUPj111+rm5ubDhgwINYXilatWqXOzs46aNAgbdy4sebKlUuLFCliE7xnzZqlFotFv/jii1iV9Spm37GnV69e+vjxY23WrJmOHj1ac+fOrT179jR+l27evKnNmjXTRYsWqWrinogyISN0460VnzNERpxB3HrrrpEjR2rHjh1Nn0k0rsVFi2Vc8PX11Tlz5qhq+A9g7969tUuXLhoUFKQzZszQbt26qcViidFYx/iUEOcbiCguxlA+evRIZ8yYoWXLljXtlmsnTpzQokWLaqdOnWy69Pbo0UNr1apltAqZzRrMBg8ebHMxY82aNZoiRYpIF1KichK8ePFi9fDwMGZgtx4vL168qBaLRbdv366qatdJzKy3c3N2dtZmzZoZd2Lo27evMYY8trfmi2+XL1/WmjVr6jfffKOq4eHRzc3N6MI/c+ZMY92YdmWNzzk44qo31NOnT3XVqlV679499fPzUzc3N2OfWm8B5e3tbdPCnViDd0LpYXblyhXNnj27Ojg46Pfff6+qtscSa/AeMGCAze9IVMLc9evXtWTJkkYvrH/++Udz5MgR6Q4s48aN00KFCsWqEePmzZvG0DHV8M/FmTNntGTJkjbBOyQkRH/88UfT56gxw9SpU7Vw4cJ65MgRHTp0qKZKlUrr1atns87QoUO1cOHC/7nZxOMaoRtvtficITLiDOJeXl6aNm1au8wgnhDFRYulmV68eKETJkxQi8Wi7du3171792pYWJiWKlVKx44dq6rhPSd69+6tOXLkMH6IE4v/0nwDr/L48eNotRLGhL+/vxYpUsS4h7uPj49mzJgxzrp8rl69WitXrqylSpXSbNmyRTrerFmzRp2cnLRz585RbnFSDR9L6uDgEOkzEhAQoEWKFDHtItSpU6eM2ZitobNXr176/vvvR3uypITo6tWrOnLkSL127ZpevXpVCxYsqD169NC7d+9q69at1WKx6PTp02NdTnzOwRFXvaGsLXYTJ07Uhg0bGt/16dOna7t27bRevXqm3UUjriWEHmbXrl3TtGnTasaMGbV8+fLGRcWI38tvvvlGc+fOrUOGDHnjZytiGL9+/brmy5dPnzx5YgRu650WVMOPY1axbcS4evWqurm5GfO3WOtx+vRpzZYtm9asWTPRNiZEvAhauXJlbdy4sYaGhmrz5s21ePHi2rdvX/3222+1c+fOmjZt2jj7nfovI3TjPyG+bllg1gziCVFCn/U1Ko4fP6516tTRihUrar9+/XTz5s3apEkTm3u5Wru3JSb/tfkG4tOJEyc0b968mitXLp04cWKctTz5+flp5syZ9cMPP9QhQ4aog4ODtm3bNlLXS+ssv9evX4/W9n/55RdNkSKFDh06VM+dO6c3btzQESNGaK5cuUzrPRDR6dOndfjw4Zo2bdo3TsKUEP17BnFrSLGeGI8YMUIbNGhgHF+GDRumOXPm1AwZMtild1R8tpDGRW8oa1jq3LmzVq5cWR88eKBPnz7VRo0aGd3OVWN/q7WEIiH0MLt8+bKeP39ePT091cvL66XB++eff47yXQw2bNig3377rQYFBWm5cuV0zpw56urqqj4+Psa52sWLF43bMarapxt0vnz5bMaMq4afz3h7e6vFYtEKFSokuttbvWwyWDc3N/3222/1yZMnOmzYMK1atap6eXlp27ZtE+UxNTEidOM/gVsWIKquX7+uP/30k5YoUUKdnJzU3d1dR4wYEd/VirX/2nwD8enIkSNau3btONuXZ8+e1UmTJtmM2d25c6cmT55cO3XqFCl4x6RbdlhYmC5evFjTpEmjuXPnVk9PT82ZM2eczNx/5MgRfe+997RgwYLxcqu12HjdfatHjRpl7L+mTZvq+++/b6zXv39/nTdvnj548MBudYnPFtK46g114MABTZ48uRYpUkTz5cunRYsWjbO7aMS1uOxhFvFWgMePH9czZ84YFzBOnDihnp6eWq5cOSN4T5ky5Y0Tj0UMzIcPH9YMGTLoggUL9P79+9q2bVtNnTq1Nm3a1OY1Q4YMUS8vrxi953/fQnbHjh2qqjpt2jQtWbKkcScPq169eun27dsT3aSwr5sMtnnz5kZPvbCwMA0ODn5rvx8JkUVVVYD/gAMHDsiMGTMkbdq08sEHH0jhwoXju0pIwJ4/fy5DhgyRb7/9VtKnTy/nz5+XNGnSxHe1Yu3ChQvSt29fCQ4Olo4dO0r79u1l1KhRcunSJZkyZYpkyJAhvqv4VggODhZHR0dTy1BVuXfvnpQoUUJu3bolnTt3lhkzZhjP79q1S2rXri0dO3aUkSNHSq5cuWJd5qVLl+Svv/6S0NBQKVasmOTMmTPW23yTp0+fypEjR8TNzc0u7yGu3LhxQypUqCDVq1eXESNGyPPnz6VChQry0Ucfye3bt2XPnj3i5uYmI0aMkGPHjskHH3wgQ4YMkcDAQNmwYYPs379f8uXLZ9c6/f7779KzZ0/JkyePjBo1SgoUKGDX7b9OXHwnRET8/f1l1apV4uzsLAMHDpRkyZLJixcvJFmyZKaXHdfi6jhjsVhk1apV0r9/f3FwcJCLFy9K69atpXPnzlKrVi35448/pE2bNnL//n2pWrWqrFixQo4ePSrFihWLtL2lS5dK8eLFjc/e+fPnZeXKlXL//n2ZOHGiiIj88ccf0rZtW8mePbs0atRIXF1dZcuWLbJw4ULZvXu3FC9ePEbvYc2aNTJgwABJmTKlBAQESJcuXaRVq1aycuVK2bVrl5QqVUrq1Kkju3btkuXLl8vvv/+eqI45VocPH5apU6dKkSJFZPXq1eLl5SUvXryQffv2Sffu3WXAgAHGPkEcis/ED8Q1blmAqIj4Gdm2bVuiu9L9Jv+l+QbeVhE/o9u3b1cPDw+tWLGi+vn52ay3a9cuYyb6xDp5VGL2phnEvb29tWnTprp06VKdPHmyFi1aVL29vU0dX5nY5+CILlryYm/fvn2aOnVq/e677/Ts2bO6du1arVGjhtatW1d9fX1VVfXGjRvau3dv7dmz5ytvfRUYGKiVK1c2Juy6e/eu5siRQx0cHGxuX6Ua/jlt27aturm5afHixbVOnTqx6qH4qlvI+vj46I4dO3T27NlaokQJLVSokJYsWTLRjXGOzmSw/N7HD0I3ALzE235x5r8038DbyBqgrV08fX191c3NTdu1a6f+/v426+7bty9Rzrr7tnjTDOI1atTQli1b6t69e1VV42Sm+7dhDg6Yz/o7OG7cOK1Zs6bNc/v27dOqVatqly5dbJa/afyzdR6DEydO6N27d/XAgQOaO3duLVWqlB4+fNhm3eDgYL1//77ev38/VveOftUtZN999111dnbWNm3aGLeNDQoKSnR3RnjbJ4N9W9C9HACARMTX11dWr14t9+/fl0KFCkm3bt0kS5Ys8uuvv4qPj49UqlRJBg0aFO0umDDPiRMnpGnTppI9e3b5/vvvbYY3bdy4UT755BMpVKiQzJ07VxwcHOKxpsD/6P93QR4/frysW7dOdu3aZXw+LRaLLF26VDp06CDnz5+PVjfsoKAgqVy5shQpUkSmT58u58+flxYtWkjNmjXlo48+kqJFi4qISFhYmCRJkiTW7+PZs2eydu1aKVWqlKRPn15q1aolpUqVkh9++EEWL14s77//vtSpU0dmzJghefLkiXV58eXEiRMyaNAgefTokZQpU0bq1asns2bNksGDB0vFihVFROT+/fuSLl26+K3of1TsP8kAACBOrFmzRho1aiQhISFy8+ZNWb16tZQtW1YuX74sderUkdmzZ8vhw4dl5MiR8scff8R3dfH/ihUrJmvWrJHHjx/LtGnT5NSpU8ZzDRs2lEmTJsmECRMI3EhQrGN+PT095ciRI7Jr1y6xWCzG8jx58oiHh4eEhYVFa7vOzs4yd+5cOXfunAwePFg8PT1lyZIlsn37dpkyZYqcPHlSRMQugVtEJEWKFNK4cWPx8PCQTZs2iaOjo4wePdp4j9WqVZO//vor0Y/7L1asmPz000/Ss2dP2bVrl7Ro0UJOnDghmzZtMtYhcMcfQjcAAInArVu3ZPTo0TJ27FiZM2eO/PrrrzJv3jzJnz+/VK9eXW7duiW1a9eW6dOny6VLlyRjxozxXWVEUKxYMZk7d64cOXJEpk6dKn/++afxXJ06dcTV1TUeaweEt2yLhLeYbt++XU6cOCEiIi1btjQmHdu0aZPcu3dPwsLCZPny5SIikjp16miX5eXlJbNnzxZ/f3/5+OOPpVChQrJ48WLZvXu3jB492ub7YQ/WCecuXrwoDx8+FCcnJxEROX78uLz77rty7tw5yZ07t13LjA8uLi7Svn17OXz4sPTo0UOuXLkic+bMkYcPH8Z31f7z6F4OAEAC9+LFC3n06JF4enrKwoULpXbt2iIiEhoaKidPnpQuXbpI586d5cMPP5QkSZLIkydPJFWqVPFca7xMfM4gDrzJqlWrpEePHpIkSRLJkSOH1KxZU7788ksREfHx8ZF58+ZJvnz5JE2aNHL+/HnZtm2blCxZMsbl/f7779KlSxcpVaqUfPXVV3Ls2DHp06ePbN26VbJnz26vt2VTXoUKFcTLy0scHR3Fz89P9uzZ89KZ1hMrjTAz+W+//Sb58uXjol4CQEs3AAAJ2NGjR6V///7y/PlzyZMnj+zcudN4LmnSpFKsWDFJliyZnDlzxuiOmTJlyniqLd6kZMmS8u2338q1a9ckbdq08V0dQETCg9rDhw9l1qxZMnXqVNm1a5e8++674uvrK927dxcRke+//15Wrlwpffr0kQ4dOsjhw4djFbhFwr8Pc+fOlRMnToiPj4+ULFlSDh8+bErgtpa3Y8cOcXd3lwIFCsj+/fvfqsAtEt5l3tqmWqtWLQJ3ApG4By8AAPCW27t3r+zatUsuXboklStXlm3btknp0qWlefPmIhJ+gpUjRw5Jly6dcaLF/VcTtjJlysiWLVvi5L7VwOtYW0WDg4NFJLyrePXq1SVnzpzSv39/SZs2rfzwww/SpUsXmTt3rjRu3NjudShZsqTMmDFDPv74Y3ny5InpF6MqVKgg5cqVsxmf/rZ5W99XYkb3cgAAEqCnT58aLdZVqlSRDBkyyMqVK6VVq1Zy5coVqVixolSqVEl2794tP/30kxw6dIiuygCibd26dTJhwgRxcXGRc+fOib+/v3FB6OHDhzJ//nxZsGCB5MmTR5YtW2ZaPYKDg7kQhbcW3csBAEhgtm7dKj169JBff/1VREQWLlwoJ06ckNmzZ8uiRYukVq1acujQIRkxYoQcP35cdu3aReAGEGXWNjc/Pz9p06aNVKhQQVKlSiXXrl2TVq1aGeulSZNGOnfuLK1atZLr16/LtWvXTKsTgRtvM1q6AQBIQFRVfHx85IcffpD06dNLnz59pGPHjrJ48WI5evSoTJo0SfLmzSthYWFy584dSZUqlTETLwBE1fHjx+XGjRvy+++/y5AhQ+Tx48eyefNmGTRokJQqVUpWrlxprPvo0SN5/vy5pE+fPh5rDCRejOkGACABsVgs0q1bN3n06JEUKVJEVq9eLTdu3JAXL17I6dOnZf369TJgwABJkiSJZM6cOb6rCyARun//vtSvX1+uX78uAwcOFBERJycnadiwoYiIDBo0SFq1amV0J4/JbcEA/A/dywEASAC2b98uP/zwg4iE38M2Y8aM8vfff8v27duN2XX/+usv+eijj+TQoUPxWVUAiVDEzq3p0qWTRYsWiZeXl+zevVtevHghIuF3PmjUqJF89dVXsnXrVunQoUN8VRd4q9C9HACAeBYaGiqTJ0+WESNGSLt27cTHx0cqVqwoXl5e0rRpU/n0008lKChIRowYIatXr5adO3dK3rx547vaABIJ6yzlBw8elGPHjsm9e/ekTJkykiJFCvHx8RFXV1fZsmWLsf7Tp09l27ZtUqhQIY41gB0QugEASCBOnDghgwYNkkePHkmZMmWkXr16MmvWLBk8eLBUrFhRRMK7haZLly5+Kwog0Vm5cqV07dpV6tevL5cuXZKwsDApWrSodOjQQdq0aSPFixeXTZs2xXc1gbcS3csBAEggihUrJj/99JP07NlTdu3aJS1atJATJ07YnAgTuAFE1+nTp2XgwIEyadIkWbx4sfz4449y4sQJyZo1q1SpUkWWLl0qZ8+eNS7uAbAvQjcAAAmIi4uLtG/fXg4fPiw9evSQK1euyJw5c+Thw4fxXTUAiVRgYKBkzJhRfHx85OLFi1K/fn1p166djBs3TkTCb9c1e/ZsCQoKksDAwHiuLfD2IXQDAJDAqKokT55cpkyZIps2bZLDhw9LmjRp4rtaABIpi8Ui2bJlk4CAAKlatarUrVtXZs6cKSIi+/btk9WrV4uHh4f4+flJrly54rm2wNuHMd0AACRA1omPACC2AgICpHDhwvL06VPp06ePfPPNN8Zzffv2lTNnzsjSpUsZvgKYhPt0AwCQABG4AdiLm5ubLFq0SN5//31JmTKlnDt3TkJCQmTBggXy888/y549ewjcgIlo6QYAAADecqGhofLzzz9Lv379xNnZWdKkSSMpUqSQefPmScmSJeO7esBbjdANAAAA/EdcuXJFAgICJHXq1JIzZ07JlClTfFcJeOsRugEAAAAAMAmzlwMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwCAGKlevbr0798/vqsBAECCRugGACCRmjVrlqRJk0ZevHhhLHv06JEkT55cqlevbrPuzp07xWKxyN9//x3HtQQA4L+N0A0AQCLl7e0tjx49kiNHjhjL9uzZI1mzZpVDhw5JcHCwsXzHjh2SO3du8fDwiFYZqmoT6gEAQPQQugEASKTy588v2bJlk507dxrLdu7cKU2aNBF3d3c5ePCgzXJvb28JCQmRvn37SpYsWcTR0VEqV64sfn5+NutZLBbZvHmzlC5dWhwcHGTv3r3y+PFj6dChg6ROnVqyZcsmX331VaT6zJgxQ/LlyyeOjo7i4uIiLVq0MPX9AwCQGBC6AQBIxLy9vWXHjh3G4x07dkj16tWlWrVqxvKnT5/KoUOHxNvbWwYPHiwrV66UBQsWiL+/v+TNm1fq1q0rd+/etdnu0KFD5fPPP5fTp09LsWLFZNCgQbJr1y5Zu3at/Prrr7Jz507x9/c31j9y5Ij07dtXxo4dK2fOnJEtW7ZI1apV42YnAACQgCWL7woAAICY8/b2lv79+8uLFy/k6dOn8vvvv0u1atXk+fPnMmvWLBEROXDggISEhEj16tWle/fuMn/+fKlfv76IiMyZM0e2bdsmP/74owwaNMjY7tixY6V27doiEj5O/Mcff5RffvlFatasKSIiCxYskJw5cxrrX758WZycnKRRo0aSJk0acXV1lZIlS8bVbgAAIMGipRsAgESsevXq8vjxY/Hz85M9e/aIp6enZM6cWapVq2aM6965c6fkyZNHHjx4IM+fP5dKlSoZr0+ePLmULVtWTp8+bbNdLy8v4////vtvefbsmZQrV85YliFDBsmfP7/xuHbt2uLq6ip58uSR9u3by8KFC+XJkycmvnMAABIHQjcAAIlY3rx5JWfOnLJjxw7ZsWOHVKtWTUREsmfPLrly5ZL9+/fLjh07pEaNGtHarpOTU7TWT5Mmjfj7+8vixYslW7ZsMnLkSClevLjcv38/WtsBAOBtQ+gGACCR8/b2lp07d8rOnTttbhVWtWpV2bx5sxw+fFi8vb3Fw8NDUqRIIfv27TPWef78ufj5+UmhQoVeuX0PDw9Jnjy5HDp0yFh27949OXv2rM16yZIlk1q1asnkyZPlxIkTEhAQINu3b7ffGwUAIBFiTDcAAImct7e39OrVS54/f260dIuIVKtWTXr37i3Pnj0Tb29vcXJykg8++EAGDRokGTJkkNy5c8vkyZPlyZMn0rVr11duP3Xq1NK1a1cZNGiQZMyYUbJkySIjRoyQJEn+d+1+w4YNcuHCBalataqkT59eNm3aJGFhYTZd0AEA+C8idAMAkMh5e3vL06dPpUCBAuLi4mIsr1atmjx8+NC4tZiIyOeffy5hYWHSvn17efjwoXh5ecnWrVslffr0ry3jiy++kEePHknjxo0lTZo08tFHH8mDBw+M59OlSyerVq2S0aNHS3BwsOTLl08WL14shQsXNudNAwCQSFhUVeO7EgAAAAAAvI0Y0w0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJjk/wDBFBlVOGs7QAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Playing with Grammar**\n",
        "Grammar is one of the main building blocks of language. Each human language, and programming language for that matter, has a set of rules that every person speaking it has to follow because otherwise, they risk not being understood. These grammatical rules can be uncovered using NLP and are useful for extracting data from sentences. For example, using information about the grammatical structure of text, we can parse out subjects, objects, and relationships between different entities."
      ],
      "metadata": {
        "id": "5HmqPSQFKEv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install inflect\n",
        "!pip install textacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s6rR2mqIgM-",
        "outputId": "eb1fd4d8-176c-47df-a544-33fc06c678e8"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (7.0.0)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from inflect) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect) (2.18.1)\n",
            "Requirement already satisfied: textacy in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (5.3.3)\n",
            "Requirement already satisfied: catalogue~=2.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.0.10)\n",
            "Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from textacy) (0.12.3)\n",
            "Requirement already satisfied: floret~=0.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (0.10.5)\n",
            "Requirement already satisfied: jellyfish>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.0.3)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.4.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.25.2)\n",
            "Requirement already satisfied: pyphen>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (0.15.0)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.2.2)\n",
            "Requirement already satisfied: spacy~=3.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.7.4)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.10/dist-packages (from textacy) (4.66.2)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->textacy) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->textacy) (3.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.4.8)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (4.11.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy~=3.0->textacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy~=3.0->textacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy~=3.0->textacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy~=3.0->textacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy~=3.0->textacy) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neuralcoref"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7W1P6gZKfHK",
        "outputId": "08107849-5b05-403b-bfff-07f01b4006c5"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neuralcoref\n",
            "  Using cached neuralcoref-4.0.tar.gz (368 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from neuralcoref) (1.25.2)\n",
            "Collecting boto3 (from neuralcoref)\n",
            "  Using cached boto3-1.34.93-py3-none-any.whl (139 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from neuralcoref) (2.31.0)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from neuralcoref) (3.7.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2024.2.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (4.66.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.1.0->neuralcoref) (3.3.0)\n",
            "Collecting botocore<1.35.0,>=1.34.93 (from boto3->neuralcoref)\n",
            "  Using cached botocore-1.34.93-py3-none-any.whl (12.2 MB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->neuralcoref)\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->neuralcoref)\n",
            "  Using cached s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.93->boto3->neuralcoref) (2.8.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.0->neuralcoref) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.0->neuralcoref) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.0->neuralcoref) (4.11.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.1.0->neuralcoref) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.1.0->neuralcoref) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy>=2.1.0->neuralcoref) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=2.1.0->neuralcoref) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.1.0->neuralcoref) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.93->boto3->neuralcoref) (1.16.0)\n",
            "Building wheels for collected packages: neuralcoref\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for neuralcoref (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for neuralcoref\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for neuralcoref\n",
            "Failed to build neuralcoref\n",
            "\u001b[31mERROR: Could not build wheels for neuralcoref, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall neuralcoref\n",
        "# git clone https://github.com/huggingface/neuralcoref.git\n",
        "# cd neuralcoref\n",
        "# !pip install -r requirements.txt\n",
        "# !pip install -e"
      ],
      "metadata": {
        "id": "5WILBsTsKxDF"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import time\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNTVgjcaNewK",
        "outputId": "9432b458-b4cc-4d04-ea89-b7ea0711f383"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_file(filename):\n",
        "    file = open(filename, \"r\", encoding=\"utf-8\")\n",
        "    return file.read()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return text\n",
        "\n",
        "def pos_tag_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    words = [token.text for token in doc]\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    return list(zip(words, pos))\n",
        "\n",
        "def pos_tag(text):\n",
        "    text = preprocess_text(text)\n",
        "    words_with_pos = pos_tag_nltk(text)\n",
        "    return words_with_pos\n",
        "\n",
        "def tokenize_nltk(text):\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "def pos_tag_nltk(text):\n",
        "    words = tokenize_nltk(text)\n",
        "    words_with_pos = nltk.pos_tag(words)\n",
        "    return words_with_pos\n",
        "\n",
        "def main():\n",
        "    sherlock_holmes_text = read_text_file(\"/content/drive/MyDrive/_Python/Python-Natural-Language-Processing/Chapter01/sherlock_holmes_1.txt\")\n",
        "    sherlock_holmes_text = preprocess_text(sherlock_holmes_text)\n",
        "    words_with_pos = pos_tag(sherlock_holmes_text)\n",
        "    print(words_with_pos)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start = time.time()\n",
        "    main()\n",
        "    print(\"%s s\" % (time.time() - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrffq3N3LwMS",
        "outputId": "7cdfb737-c39e-4c2e-86ca-04bd37d47554"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('To', 'TO'), ('Sherlock', 'NNP'), ('Holmes', 'NNP'), ('she', 'PRP'), ('is', 'VBZ'), ('always', 'RB'), ('_the_', 'JJ'), ('woman', 'NN'), ('.', '.'), ('I', 'PRP'), ('have', 'VBP'), ('seldom', 'VBN'), ('heard', 'RB'), ('him', 'PRP'), ('mention', 'VB'), ('her', 'PRP'), ('under', 'IN'), ('any', 'DT'), ('other', 'JJ'), ('name', 'NN'), ('.', '.'), ('In', 'IN'), ('his', 'PRP$'), ('eyes', 'NNS'), ('she', 'PRP'), ('eclipses', 'VBZ'), ('and', 'CC'), ('predominates', 'VBZ'), ('the', 'DT'), ('whole', 'NN'), ('of', 'IN'), ('her', 'PRP$'), ('sex', 'NN'), ('.', '.'), ('It', 'PRP'), ('was', 'VBD'), ('not', 'RB'), ('that', 'IN'), ('he', 'PRP'), ('felt', 'VBD'), ('any', 'DT'), ('emotion', 'NN'), ('akin', 'NN'), ('to', 'TO'), ('love', 'VB'), ('for', 'IN'), ('Irene', 'NNP'), ('Adler', 'NNP'), ('.', '.'), ('All', 'DT'), ('emotions', 'NNS'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('one', 'CD'), ('particularly', 'RB'), (',', ','), ('were', 'VBD'), ('abhorrent', 'JJ'), ('to', 'TO'), ('his', 'PRP$'), ('cold', 'NN'), (',', ','), ('precise', 'NN'), ('but', 'CC'), ('admirably', 'RB'), ('balanced', 'VBD'), ('mind', 'NN'), ('.', '.'), ('He', 'PRP'), ('was', 'VBD'), (',', ','), ('I', 'PRP'), ('take', 'VBP'), ('it', 'PRP'), (',', ','), ('the', 'DT'), ('most', 'RBS'), ('perfect', 'JJ'), ('reasoning', 'NN'), ('and', 'CC'), ('observing', 'VBG'), ('machine', 'NN'), ('that', 'IN'), ('the', 'DT'), ('world', 'NN'), ('has', 'VBZ'), ('seen', 'VBN'), (',', ','), ('but', 'CC'), ('as', 'IN'), ('a', 'DT'), ('lover', 'NN'), ('he', 'PRP'), ('would', 'MD'), ('have', 'VB'), ('placed', 'VBN'), ('himself', 'PRP'), ('in', 'IN'), ('a', 'DT'), ('false', 'JJ'), ('position', 'NN'), ('.', '.'), ('He', 'PRP'), ('never', 'RB'), ('spoke', 'VBD'), ('of', 'IN'), ('the', 'DT'), ('softer', 'JJR'), ('passions', 'NNS'), (',', ','), ('save', 'VBP'), ('with', 'IN'), ('a', 'DT'), ('gibe', 'NN'), ('and', 'CC'), ('a', 'DT'), ('sneer', 'NN'), ('.', '.'), ('They', 'PRP'), ('were', 'VBD'), ('admirable', 'JJ'), ('things', 'NNS'), ('for', 'IN'), ('the', 'DT'), ('observer—excellent', 'NN'), ('for', 'IN'), ('drawing', 'VBG'), ('the', 'DT'), ('veil', 'NN'), ('from', 'IN'), ('men', 'NNS'), ('’', 'VBP'), ('s', 'JJ'), ('motives', 'NNS'), ('and', 'CC'), ('actions', 'NNS'), ('.', '.'), ('But', 'CC'), ('for', 'IN'), ('the', 'DT'), ('trained', 'JJ'), ('reasoner', 'NN'), ('to', 'TO'), ('admit', 'VB'), ('such', 'JJ'), ('intrusions', 'NNS'), ('into', 'IN'), ('his', 'PRP$'), ('own', 'JJ'), ('delicate', 'NN'), ('and', 'CC'), ('finely', 'RB'), ('adjusted', 'VBD'), ('temperament', 'NN'), ('was', 'VBD'), ('to', 'TO'), ('introduce', 'VB'), ('a', 'DT'), ('distracting', 'NN'), ('factor', 'NN'), ('which', 'WDT'), ('might', 'MD'), ('throw', 'VB'), ('a', 'DT'), ('doubt', 'NN'), ('upon', 'IN'), ('all', 'PDT'), ('his', 'PRP$'), ('mental', 'JJ'), ('results', 'NNS'), ('.', '.'), ('Grit', 'NNP'), ('in', 'IN'), ('a', 'DT'), ('sensitive', 'JJ'), ('instrument', 'NN'), (',', ','), ('or', 'CC'), ('a', 'DT'), ('crack', 'NN'), ('in', 'IN'), ('one', 'CD'), ('of', 'IN'), ('his', 'PRP$'), ('own', 'JJ'), ('high-power', 'NN'), ('lenses', 'NNS'), (',', ','), ('would', 'MD'), ('not', 'RB'), ('be', 'VB'), ('more', 'RBR'), ('disturbing', 'JJ'), ('than', 'IN'), ('a', 'DT'), ('strong', 'JJ'), ('emotion', 'NN'), ('in', 'IN'), ('a', 'DT'), ('nature', 'NN'), ('such', 'JJ'), ('as', 'IN'), ('his', 'PRP$'), ('.', '.'), ('And', 'CC'), ('yet', 'RB'), ('there', 'EX'), ('was', 'VBD'), ('but', 'CC'), ('one', 'CD'), ('woman', 'NN'), ('to', 'TO'), ('him', 'PRP'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('woman', 'NN'), ('was', 'VBD'), ('the', 'DT'), ('late', 'JJ'), ('Irene', 'NNP'), ('Adler', 'NNP'), (',', ','), ('of', 'IN'), ('dubious', 'JJ'), ('and', 'CC'), ('questionable', 'JJ'), ('memory', 'NN'), ('.', '.')]\n",
            "0.04171109199523926 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import inflect"
      ],
      "metadata": {
        "id": "6LYd4_hLK71O"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the text file\n",
        "file = open(\"/content/drive/MyDrive/_Python/Python-Natural-Language-Processing/Chapter01/sherlock_holmes_1.txt\", \"r\", encoding=\"utf-8\")\n",
        "sherlock_holmes_text = file.read()"
      ],
      "metadata": {
        "id": "Aa95e0frL2wW"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove newlines for better readability\n",
        "sherlock_holmes_text = sherlock_holmes_text.replace(\"\\n\", \" \")"
      ],
      "metadata": {
        "id": "rS_BOiWpMLej"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do part of speech tagging\n",
        "words_with_pos = pos_tag_nltk(sherlock_holmes_text)"
      ],
      "metadata": {
        "id": "kqVQatYuMQ1D"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the get_nouns function, whic will filter out the nouns from all the words\n",
        "def get_nouns(words_with_pos):\n",
        "  noun_set = [\"NN\", \"NNS\", \"NNP\", \"NNPS\"]\n",
        "  nouns = [word for word in words_with_pos if word[1] in noun_set]\n",
        "  return nouns"
      ],
      "metadata": {
        "id": "BJwBrYAZMdjP"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the preceding function on the list of POS-tagged words and prints it\n",
        "nouns = get_nouns(words_with_pos)\n",
        "print(nouns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rYbliMYOLXd",
        "outputId": "7892fa10-d61e-4c65-96f9-c813ec4d1a36"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Sherlock', 'NNP'), ('Holmes', 'NNP'), ('woman', 'NN'), ('name', 'NN'), ('eyes', 'NNS'), ('whole', 'NN'), ('sex', 'NN'), ('emotion', 'NN'), ('akin', 'NN'), ('Irene', 'NNP'), ('Adler', 'NNP'), ('emotions', 'NNS'), ('cold', 'NN'), ('precise', 'NN'), ('mind', 'NN'), ('reasoning', 'NN'), ('machine', 'NN'), ('world', 'NN'), ('lover', 'NN'), ('position', 'NN'), ('passions', 'NNS'), ('gibe', 'NN'), ('sneer', 'NN'), ('things', 'NNS'), ('observer—excellent', 'NN'), ('veil', 'NN'), ('men', 'NNS'), ('motives', 'NNS'), ('actions', 'NNS'), ('reasoner', 'NN'), ('intrusions', 'NNS'), ('delicate', 'NN'), ('temperament', 'NN'), ('distracting', 'NN'), ('factor', 'NN'), ('doubt', 'NN'), ('results', 'NNS'), ('Grit', 'NNP'), ('instrument', 'NN'), ('crack', 'NN'), ('high-power', 'NN'), ('lenses', 'NNS'), ('emotion', 'NN'), ('nature', 'NN'), ('woman', 'NN'), ('woman', 'NN'), ('Irene', 'NNP'), ('Adler', 'NNP'), ('memory', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_lBsxtPwXXmz"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to view the result in table\n",
        "# convert the list of noun tuples into a pandas df\n",
        "df = pd.DataFrame(nouns, columns=[\"word\", \"pos\"])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OMJBIRtEOU-R",
        "outputId": "309e8128-500b-48ec-9db6-f4152bb542f9"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       word  pos\n",
              "0  Sherlock  NNP\n",
              "1    Holmes  NNP\n",
              "2     woman   NN\n",
              "3      name   NN\n",
              "4      eyes  NNS"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3f13929-73f4-4115-9b58-ef3d49358d6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sherlock</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Holmes</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>woman</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>name</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eyes</td>\n",
              "      <td>NNS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3f13929-73f4-4115-9b58-ef3d49358d6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3f13929-73f4-4115-9b58-ef3d49358d6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3f13929-73f4-4115-9b58-ef3d49358d6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9b5b9867-115e-47df-8535-24a1660d6715\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b5b9867-115e-47df-8535-24a1660d6715')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9b5b9867-115e-47df-8535-24a1660d6715 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 49,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"Grit\",\n          \"observer\\u2014excellent\",\n          \"veil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"NNP\",\n          \"NN\",\n          \"NNS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine whether a noun is singular or plural, we have two options. The first option is to use the NLTK tags, where NN indicates a singular noun and NNS indicates a plural noun. The following function uses the NLTK tags and returns True if the input noun is plural"
      ],
      "metadata": {
        "id": "aClWrhO6Q-JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_plural_nltk(noun_info):\n",
        "  pos = noun_info[1]\n",
        "  if (pos == \"NNS\"):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "AvIAPm_kPjMP"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The other option is to use the WordNetLemmatizer class in the nltk.stem package. The following function returns True if the noun is plural"
      ],
      "metadata": {
        "id": "tTeJl9WKRa1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_plural_wn(noun):\n",
        "  wnl = WordNetLemmatizer()\n",
        "  lemma = wnl.lemmatize(noun, 'n')\n",
        "  plural = True if noun is not lemma else False\n",
        "  return plural"
      ],
      "metadata": {
        "id": "1070k1RsP6y9"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following function will change a singular noun into plural\n",
        "def get_plural(singular_noun):\n",
        "  p = inflect.engine()\n",
        "  return p.plural(singular_noun)"
      ],
      "metadata": {
        "id": "eSuRw-r5RytL"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The followint function will change a plural nounr into singular\n",
        "def get_singular(plural_noun):\n",
        "  p = inflect.engine()\n",
        "  plural = p.singular_noun(plural_noun)\n",
        "  if (plural):\n",
        "    return plural\n",
        "  else:\n",
        "    plural_noun"
      ],
      "metadata": {
        "id": "lMBEvSEtSIXx"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now use the two preceding functions to return a list of nouns changed into plural or singular, depending on the original noun. The following code uses the is_plural_wn function to determine if the noun is plural. We can also use the is_plural_nltk function"
      ],
      "metadata": {
        "id": "J7AmwMxZSpyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plurals_wn(words_with_pos):\n",
        "  other_nouns = []\n",
        "  for noun_info in words_with_pos:\n",
        "    word = noun_info[0]\n",
        "    plural = is_plural_wn(word)\n",
        "    if (plural):\n",
        "      singular = get_singular(word)\n",
        "      other_nouns.append(singular)\n",
        "    else:\n",
        "      plural = get_plural(word)\n",
        "      other_nouns.append(plural)\n",
        "  return other_nouns"
      ],
      "metadata": {
        "id": "81_GAA6RSkET"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qsthihNT8Uu",
        "outputId": "b2efc629-5469-4780-b40e-3fd54062e78d"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use the preceding function to return a list of changed nouns\n",
        "other_nouns_wn = plurals_wn(nouns)\n",
        "print(other_nouns_wn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUuuaSFTSr_A",
        "outputId": "dafb6e6e-55ee-47ed-c68b-7c2e82408ffc"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sherlocks', 'Holmeses', 'women', 'names', 'eye', 'wholes', 'sexes', 'emotions', 'akins', 'Irenes', 'Adlers', 'emotion', 'colds', 'precises', 'minds', 'reasonings', 'machines', 'worlds', 'lovers', 'positions', 'passion', 'gibes', 'sneers', 'thing', 'observer—excellents', 'veils', 'mens', 'motive', 'action', 'reasoners', 'intrusion', 'delicates', 'temperaments', 'distractings', 'factors', 'doubts', 'result', 'Grits', 'instruments', 'cracks', 'high-powers', 'lens', 'emotions', 'natures', 'women', 'women', 'Irenes', 'Adlers', 'memories']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Getting the dependency parse**\n",
        "A dependency parse is a tool that shows dependencies in a sentence. For example, in the sentence The cat wore a hat, the root of the sentence in the verb, wore, and both the subject, the cat, and the object, a hat, are dependents. The dependency parse can be very useful in many NLP tasks since it shows the grammatical structure of the sentence, along with the subject, the main verb, the object, and so on. It can be then used in downstream processing."
      ],
      "metadata": {
        "id": "cmdIvftZUQ_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "3d1XFQuRTXk7"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the sentence to be parsed\n",
        "sentence = 'I have seldom heard him mention her under any other name.'"
      ],
      "metadata": {
        "id": "3CV2ymGGUxxW"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the spacy engine\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "zB_URG7VVBRc"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process the sentence using the spacy engine\n",
        "doc = nlp(sentence)"
      ],
      "metadata": {
        "id": "cWSQMu2qVFTg"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the dependency info will be contained in the doc object.\n",
        "# we can see the dependency tags by looping throught the tokens in doc\n",
        "for token in doc:\n",
        "  print(token.text, \"\\t\", token.dep_, \"\\t\", spacy.explain(token.dep_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_V1l7I5VLWF",
        "outputId": "b886d0fa-1c0a-4d07-d2be-00ab03b86fac"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I \t nsubj \t nominal subject\n",
            "have \t aux \t auxiliary\n",
            "seldom \t advmod \t adverbial modifier\n",
            "heard \t ROOT \t root\n",
            "him \t nsubj \t nominal subject\n",
            "mention \t ccomp \t clausal complement\n",
            "her \t dobj \t direct object\n",
            "under \t prep \t prepositional modifier\n",
            "any \t det \t determiner\n",
            "other \t amod \t adjectival modifier\n",
            "name \t pobj \t object of preposition\n",
            ". \t punct \t punctuation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To explore the dependency parse structure, we can use the attributes of the Token class. Using its ancestors and children attributes, we can get the tokens that this token depends on and the tokens that depend on it, respectively."
      ],
      "metadata": {
        "id": "vMqrd2zCbqE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token.text)\n",
        "  ancestors = [ancestor.text for ancestor in token.ancestors]\n",
        "  print(ancestors)\n",
        "#  children = [t.text for t in token.children]\n",
        "#  print(children)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQgJtKytVjzs",
        "outputId": "49f41f83-63da-4c20-862b-a39612553400"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "['heard']\n",
            "have\n",
            "['heard']\n",
            "seldom\n",
            "['heard']\n",
            "heard\n",
            "[]\n",
            "him\n",
            "['mention', 'heard']\n",
            "mention\n",
            "['heard']\n",
            "her\n",
            "['mention', 'heard']\n",
            "under\n",
            "['mention', 'heard']\n",
            "any\n",
            "['name', 'under', 'mention', 'heard']\n",
            "other\n",
            "['name', 'under', 'mention', 'heard']\n",
            "name\n",
            "['under', 'mention', 'heard']\n",
            ".\n",
            "['heard']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to see all the children token\n",
        "for token in doc:\n",
        "  print(token.text)\n",
        "  children = [t.text for t in token.children]\n",
        "  print(children)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1vJWK5VbqZN",
        "outputId": "e435e3bb-f331-45ea-b956-9219380ae554"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "[]\n",
            "have\n",
            "[]\n",
            "seldom\n",
            "[]\n",
            "heard\n",
            "['I', 'have', 'seldom', 'mention', '.']\n",
            "him\n",
            "[]\n",
            "mention\n",
            "['him', 'her', 'under']\n",
            "her\n",
            "[]\n",
            "under\n",
            "['name']\n",
            "any\n",
            "[]\n",
            "other\n",
            "[]\n",
            "name\n",
            "['any', 'other']\n",
            ".\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we also can see the subtree that the token is in\n",
        "for token in doc:\n",
        "  print(token.text)\n",
        "  subtree = [t.text for t in token.subtree]\n",
        "  print(subtree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG5ZWlSZc05_",
        "outputId": "27a66445-1a40-482e-dd95-9a365b236bc5"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "['I']\n",
            "have\n",
            "['have']\n",
            "seldom\n",
            "['seldom']\n",
            "heard\n",
            "['I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', '.']\n",
            "him\n",
            "['him']\n",
            "mention\n",
            "['him', 'mention', 'her', 'under', 'any', 'other', 'name']\n",
            "her\n",
            "['her']\n",
            "under\n",
            "['under', 'any', 'other', 'name']\n",
            "any\n",
            "['any']\n",
            "other\n",
            "['other']\n",
            "name\n",
            "['any', 'other', 'name']\n",
            ".\n",
            "['.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Splitting sentences into clauses**\n",
        "When we work with text, we frequently deal with compound (sentences with two parts that are equally important) and complex sentences (sentences with one part depending on another). It is sometimes useful to split these composite sentences into its component clauses for easier processing down the line.\n",
        "\n",
        "We will work with two sentences, He eats cheese, but he won't eat ice cream and If it rains later, we won't be able to go to the park. Other sentences may turn out to be more complicated to deal with..."
      ],
      "metadata": {
        "id": "IQN9WNzRdIJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "GC_XPIiwdCrZ"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the spacy engine\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "ML4JPiTreGPi"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the sentence\n",
        "sentence = \"He eats cheese, but he won't eat ice cream.\""
      ],
      "metadata": {
        "id": "MprDHMMzeNx_"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process the sentence with spacy engine\n",
        "doc = nlp(sentence)"
      ],
      "metadata": {
        "id": "UFAeUfR7eWqi"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is instructive to look at the structure of the input sentence by printing out the part of speech, dependency tag, ancestors, and children of each token. This can be accomplished using the following code:"
      ],
      "metadata": {
        "id": "gGay4crXeiKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  ancestors = [ancestor.text for ancestor in token.ancestors]\n",
        "  children = [t.text for t in token.children]\n",
        "  print(token.text, \"\\t\", token.pos_, \"\\t\", token.dep_, \"\\t\", ancestors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaR2bafseb-D",
        "outputId": "dcbb6fb1-e331-4e8b-e8d9-4032929e472c"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He \t PRON \t nsubj \t ['eats']\n",
            "eats \t VERB \t ROOT \t []\n",
            "cheese \t NOUN \t dobj \t ['eats']\n",
            ", \t PUNCT \t punct \t ['eats']\n",
            "but \t CCONJ \t cc \t ['eats']\n",
            "he \t PRON \t nsubj \t ['eat', 'eats']\n",
            "wo \t AUX \t aux \t ['eat', 'eats']\n",
            "n't \t PART \t neg \t ['eat', 'eats']\n",
            "eat \t VERB \t conj \t ['eats']\n",
            "ice \t NOUN \t compound \t ['cream', 'eat', 'eats']\n",
            "cream \t NOUN \t dobj \t ['eat', 'eats']\n",
            ". \t PUNCT \t punct \t ['eat', 'eats']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  ancestors = [t.text for t in token.ancestors]\n",
        "  children = [t.text for t in token.children]\n",
        "  print(token.text, \"\\t\", token.i, \"\\t\",\n",
        "        token.pos_, \"\\t\", token.dep_, \"\\t\",\n",
        "        ancestors, \"\\t\", children)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH8Aa-1te23l",
        "outputId": "b9149ddc-2040-4bc4-d991-6ac8f46c9575"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He \t 0 \t PRON \t nsubj \t ['eats'] \t []\n",
            "eats \t 1 \t VERB \t ROOT \t [] \t ['He', 'cheese', ',', 'but', 'eat']\n",
            "cheese \t 2 \t NOUN \t dobj \t ['eats'] \t []\n",
            ", \t 3 \t PUNCT \t punct \t ['eats'] \t []\n",
            "but \t 4 \t CCONJ \t cc \t ['eats'] \t []\n",
            "he \t 5 \t PRON \t nsubj \t ['eat', 'eats'] \t []\n",
            "wo \t 6 \t AUX \t aux \t ['eat', 'eats'] \t []\n",
            "n't \t 7 \t PART \t neg \t ['eat', 'eats'] \t []\n",
            "eat \t 8 \t VERB \t conj \t ['eats'] \t ['he', 'wo', \"n't\", 'cream', '.']\n",
            "ice \t 9 \t NOUN \t compound \t ['cream', 'eat', 'eats'] \t []\n",
            "cream \t 10 \t NOUN \t dobj \t ['eat', 'eats'] \t ['ice']\n",
            ". \t 11 \t PUNCT \t punct \t ['eat', 'eats'] \t []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the following function to find the root token of the sentence, which is usually the main verb. In instances where there is a dependent clause, it is the verb of the independent clause:"
      ],
      "metadata": {
        "id": "4oXpX80uiEyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_root_of_sentence(doc):\n",
        "  root_token = None\n",
        "  for token in doc:\n",
        "    if token.dep_ == 'ROOT':\n",
        "      root_token = token\n",
        "      break\n",
        "  return root_token"
      ],
      "metadata": {
        "id": "11qf434ufRzy"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the root token of the sentence\n",
        "root_token = find_root_of_sentence(doc)\n",
        "print(root_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZkhBAwaii0L",
        "outputId": "2c50380e-eaa1-4287-9c52-ff8d34305739"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can now use the following function to find the other verbs in the sentence\n",
        "def find_other_verbs(doc, root_token):\n",
        "  other_verbs = []\n",
        "  for token in doc:\n",
        "    ancestors = list(token.ancestors)\n",
        "    if (token.pos_ == \"VERB\" and len(ancestors) == 1\n",
        "        and ancestors[0] == root_token):\n",
        "      other_verbs.append(token)\n",
        "      return other_verbs"
      ],
      "metadata": {
        "id": "_H_phylVircc"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the preceding function to find the remaining verbs in the sentence\n",
        "other_verbs = find_other_verbs(doc, root_token)\n",
        "print(other_verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnejQrIajFhD",
        "outputId": "745768f9-afee-476b-aa8d-edd9a157ddc8"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[eat]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use the following function to find the token spans for each verb\n",
        "def get_clause_token_span_for_verb(verb, doc, all_verbs):\n",
        "    first_token_index = len(doc)\n",
        "    last_token_index = 0\n",
        "    this_verb_children = list(verb.children)\n",
        "    for child in this_verb_children:\n",
        "        if (child not in all_verbs):\n",
        "            if (child.i < first_token_index):\n",
        "                first_token_index = child.i\n",
        "            if (child.i > last_token_index):\n",
        "                last_token_index = child.i\n",
        "    return(first_token_index, last_token_index)"
      ],
      "metadata": {
        "id": "xpxrZYFhjLzm"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will put together all the verbs in one array and process each using the preceding function. This will return a tuple of start and end indices for each verb's clause"
      ],
      "metadata": {
        "id": "dBDWyXztjYPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_spans = []\n",
        "all_verbs = [root_token] + other_verbs\n",
        "for other_verb in all_verbs:\n",
        "    (first_token_index, last_token_index) = \\\n",
        "     get_clause_token_span_for_verb(other_verb,\n",
        "                                    doc, all_verbs)\n",
        "    token_spans.append((first_token_index,\n",
        "                        last_token_index))"
      ],
      "metadata": {
        "id": "MhIOp772jSjq"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the start and end indices, we can now put together token spans for each clause. We sort the sentence_clauses list at the end so that the clauses are in the order they appear in the sentence:"
      ],
      "metadata": {
        "id": "dDD3T16Vjcx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_clauses = []\n",
        "for token_span in token_spans:\n",
        "    start = token_span[0]\n",
        "    end = token_span[1]\n",
        "    if (start < end):\n",
        "        clause = doc[start:end]\n",
        "        sentence_clauses.append(clause)\n",
        "sentence_clauses = sorted(sentence_clauses,\n",
        "                          key=lambda tup: tup[0])"
      ],
      "metadata": {
        "id": "xjixgt_OjaVe"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can print the final result of the processing for our initial sentence; that is, He eats cheese, but he won't eat ice cream"
      ],
      "metadata": {
        "id": "AUx_v_01jj4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clauses_text = [clause.text for clause in sentence_clauses]\n",
        "print(clauses_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIjIP2ajjhWd",
        "outputId": "91fa4263-b31a-4b23-85f7-b5aafbd37b7e"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He eats cheese,', \"he won't eat ice cream\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracting noun chunks**\n",
        "Noun chunks are known in linguistics as noun phrases. They represent nouns and any words that depend on and accompany nouns. For example, in the sentence The big red apple fell on the scared cat, the noun chunks are the big red apple and the scared cat. Extracting these noun chunks is instrumental to many other downstream NLP tasks, such as named entity recognition and processing entities and relationships between them. In this section, we will explore how to extract named entities from a piece of text."
      ],
      "metadata": {
        "id": "CuJG7KTVjzaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read the text\n",
        "text = read_text_file(\"/content/drive/MyDrive/_Python/Python-Natural-Language-Processing/Chapter01/sherlock_holmes_1.txt\")"
      ],
      "metadata": {
        "id": "wJKK7UeIjqDW"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the spacy engine and then use it to process the text\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "1SsPXLqHkFxo"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the noun chunks are contained in the doc.noun_chunks class variable. We can print out the chunks\n",
        "for noun_chunks in doc.noun_chunks:\n",
        "  print(noun_chunks.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny8UMBUBkmoc",
        "outputId": "e030a8fa-bfa4-4298-9ee4-adbc92e96623"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sherlock Holmes\n",
            "she\n",
            "the_ woman\n",
            "I\n",
            "him\n",
            "her\n",
            "any other name\n",
            "his eyes\n",
            "she\n",
            "the whole\n",
            "her sex\n",
            "It\n",
            "he\n",
            "any emotion\n",
            "Irene Adler\n",
            "All emotions\n",
            "his cold, precise but admirably balanced mind\n",
            "He\n",
            "I\n",
            "it\n",
            "the world\n",
            "a lover\n",
            "he\n",
            "himself\n",
            "a\n",
            "false position\n",
            "He\n",
            "the softer passions\n",
            "a gibe\n",
            "a sneer\n",
            "They\n",
            "admirable things\n",
            "the observer\n",
            "the veil\n",
            "men’s motives\n",
            "actions\n",
            "the trained\n",
            "reasoner\n",
            "such intrusions\n",
            "his own delicate and finely\n",
            "adjusted temperament\n",
            "a distracting factor\n",
            "which\n",
            "a doubt\n",
            "all his mental results\n",
            "Grit\n",
            "a sensitive\n",
            "instrument\n",
            "a crack\n",
            "his own high-power lenses\n",
            "a strong emotion\n",
            "a nature\n",
            "his\n",
            "one woman\n",
            "him\n",
            "that woman\n",
            "the late Irene\n",
            "Adler\n",
            "dubious and questionable memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# There's more…\n",
        "Noun chunks are spaCy Span objects and have all their properties. See the official documentation at https://spacy.io/api/token.\n",
        "\n",
        "Let's explore some properties of noun chunks:"
      ],
      "metadata": {
        "id": "4ztUBOQKnD1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "UqV-s9yok1xu"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the sentence to All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind:"
      ],
      "metadata": {
        "id": "ySfAnqOonp1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\""
      ],
      "metadata": {
        "id": "h-R1IKbonLVH"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process the sentence wth the spacy engine\n",
        "doc = nlp(sentence)"
      ],
      "metadata": {
        "id": "QXnyJ8rCnsIf"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at the nound chunks in this sentence\n",
        "for noun_chunks in doc.noun_chunks:\n",
        "  print(noun_chunks.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab13s18Onxky",
        "outputId": "fda2e01a-34c5-45ae-e82e-6acb60a597eb"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All emotions\n",
            "his cold, precise but admirably balanced mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some of the basic properties of noun chunks are its start and end offsets; we can print them out\n",
        "# toheter with the noun chunks\n",
        "for noun_chunks in doc.noun_chunks:\n",
        "  print(noun_chunks.text, \"\\t\", noun_chunks.start, \"\\t\", noun_chunks.end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c_oDGmEo3Ku",
        "outputId": "67797999-88de-4ac0-c6b9-4f1c2f7edb7c"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All emotions \t 0 \t 2\n",
            "his cold, precise but admirably balanced mind \t 11 \t 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can print out the sentence where the nound chunk belongs\n",
        "for noun_chunks in doc.noun_chunks:\n",
        "  print(noun_chunks.text, \"\\t\", noun_chunks.sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM-DJwwHpp0u",
        "outputId": "81b7a62c-b3d4-417d-856c-369db8e65cc0"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All emotions \t All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n",
            "his cold, precise but admirably balanced mind \t All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just like a sentence, any noun chunk includes a root, which is the token that all other\n",
        "# tokens depend on. In a noun phrase, that is the noun:\n",
        "for noun_chunks in doc.noun_chunks:\n",
        "  print(noun_chunks.text, \"\\t\", noun_chunks.root.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN11TPoAqJrj",
        "outputId": "7daab6bd-355c-4d6f-93a0-0a3c41a56ceb"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All emotions \t emotions\n",
            "his cold, precise but admirably balanced mind \t mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another very useful property of Span is similarity, which is the semantic similarity of different texts. Let's try it out. We will load another noun chunk, emotions, and process it using spacy:"
      ],
      "metadata": {
        "id": "iojvpvfXqnuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "other_span = \"emotions\"\n",
        "other_doc = nlp(other_span)"
      ],
      "metadata": {
        "id": "726SFQNWqhFk"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can now compare it to the noun chunks in the sentence by using this code\n",
        "for noun_chunks in doc.noun_chunks:\n",
        "  print(noun_chunks.similarity(other_doc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJl7Vy4sqsTb",
        "outputId": "7901b31a-d34c-4f85-d957-5d411eb3c956"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4026422320920005\n",
            "-0.036891266129449506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-214-0a2799a3871f>:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  print(noun_chunks.similarity(other_doc))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the result makes sense, with all emotions being more similar to emotions than to his cold, precise but admirably balanced mind, we get a warning. In order to fix this, we will use the medium spacy model, which contains vector representations for words. Substitute this line for the line in step 2; the rest of the code will remain the same:"
      ],
      "metadata": {
        "id": "W_a_Bx2FrLCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi4YEhbvsdkT",
        "outputId": "2ede6669-3b7b-4538-e108-35f20d9e8a35"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_md')"
      ],
      "metadata": {
        "id": "eYgIXvE6q3PC"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\"\n",
        "doc = nlp(sentence)\n",
        "for noun_chunks in doc.noun_chunks:\n",
        "  print(noun_chunks.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e88Dc-Gts7Zl",
        "outputId": "8b733fa5-a7af-4840-c24a-f47ad19b7dec"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All emotions\n",
            "that one\n",
            "his cold, precise but admirably balanced mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for noun_chunk in doc.noun_chunks:\n",
        "    print(noun_chunk.text, \"\\t\", noun_chunk.start, \"\\t\",\n",
        "          noun_chunk.end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RRnzsbxs7Rf",
        "outputId": "f912d749-15ae-49f6-899f-8cd559fa2cf2"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All emotions \t 0 \t 2\n",
            "that one \t 4 \t 6\n",
            "his cold, precise but admirably balanced mind \t 11 \t 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for noun_chunk in doc.noun_chunks:\n",
        "    print(noun_chunk.text, \"\\t\", noun_chunk.sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ed80HCwtO4j",
        "outputId": "7f1653b4-8d43-4ee0-8215-9b4d2b66d751"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All emotions \t All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n",
            "that one \t All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n",
            "his cold, precise but admirably balanced mind \t All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like a sentence, any noun chunk includes a root, which is the token that all other tokens depend on. In a noun phrase, that is the noun"
      ],
      "metadata": {
        "id": "XMQlHj25tbh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for noun_chunk in doc.noun_chunks:\n",
        "    print(noun_chunk.text, \"\\t\", noun_chunk.root.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSd3LHlZtOzy",
        "outputId": "765e2933-0f26-45b0-efa8-86550fc2d85d"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All emotions \t emotions\n",
            "that one \t one\n",
            "his cold, precise but admirably balanced mind \t mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another very useful property of Span is similarity, which is the semantic similarity of different texts. Let's try it out. We will load another noun chunk, emotions, and process it using spacy:"
      ],
      "metadata": {
        "id": "J98ZX_8ftfAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "other_span = \"emotions\"\n",
        "other_doc = nlp(other_span)"
      ],
      "metadata": {
        "id": "5tGChv67tVhB"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the code to get the result\n",
        "for noun_chunks in doc.noun_chunks:\n",
        "  print(noun_chunks.similarity(other_doc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB2ID9-Dr-4O",
        "outputId": "16d1800d-90a9-4847-9573-ba7465d5f9fb"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6302678068015664\n",
            "0.4765202563771464\n",
            "0.5749083803745656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result shows the similarity of all emotions to emotions are the highest, 0.63, and to his cold, precise but admirably balanced mind, 0.57. We can also see that the larger model detects another noun chunk, that one.\n",
        "\n",
        "***Important note***\n",
        "\n",
        "A larger spaCy model, such as en_core_web_md, takes up more space, but is more precise."
      ],
      "metadata": {
        "id": "AVTGHdK_uKX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracting entities and relations**\n",
        "It is possible to extract triplets of the subject entity-relation-object entity from documents, which are frequently used in knowledge graphs. These triplets can then be analyzed for further relations and inform other NLP tasks, such as searches.\n",
        "\n",
        "**Getting ready**\n",
        "\n",
        "For this section, we will need another Python package based on spacy, called textacy. The main advantage of this package is that it allows regular expression-like searching for tokens based on their part of speech tags."
      ],
      "metadata": {
        "id": "D5H9wJrbvVED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "compound_sentence = \"He eats cheese, but he won’t eat ice cream.\"\n",
        "complex_sentence = \"If it rains later, we won't be able to go to the park.\"\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "verb_pos_set = [\"VERB\"]\n",
        "\n",
        "def find_root_of_sentence(doc):\n",
        "    root_token = None\n",
        "    for token in doc:\n",
        "        if (token.dep_ == \"ROOT\"):\n",
        "            root_token = token\n",
        "    return root_token\n",
        "\n",
        "def find_other_verbs(doc, root_token):\n",
        "    other_verbs = []\n",
        "    for token in doc:\n",
        "        ancestors = list(token.ancestors)\n",
        "        if (token.pos_ == \"VERB\" and len(ancestors) == 1 and ancestors[0] == root_token):\n",
        "            other_verbs.append(token)\n",
        "    return other_verbs\n",
        "\n",
        "def get_clause_token_span_for_verb(verb, doc, all_verbs):\n",
        "    first_token_index = len(doc)\n",
        "    last_token_index = 0\n",
        "    this_verb_children = list(verb.children)\n",
        "    for child in this_verb_children:\n",
        "        if (child not in all_verbs):\n",
        "            if (child.i < first_token_index):\n",
        "                first_token_index = child.i\n",
        "            if (child.i > last_token_index):\n",
        "                last_token_index = child.i\n",
        "    return(first_token_index, last_token_index)\n",
        "\n",
        "def potential_clause_contains_subj(clause):\n",
        "    contains_subj = False\n",
        "    for token in clause:\n",
        "        if (token.dep_ == \"nsubj\"):\n",
        "            contains_subj = True\n",
        "    return contains_subj\n",
        "\n",
        "def print_doc_info(doc):\n",
        "    for token in doc:\n",
        "        ancestors = [t.text for t in token.ancestors]\n",
        "        children = [t.text for t in token.children]\n",
        "        print(token.text, \"\\t\", token.i, \"\\t\", token.pos_, \"\\t\", token.dep_, \"\\t\", ancestors, \"\\t\", children)\n",
        "\n",
        "\n",
        "def get_clauses(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    print_doc_info(doc)\n",
        "    # Find the root token\n",
        "    root_token = find_root_of_sentence(doc)\n",
        "    # Find the other verbs\n",
        "    other_verbs = find_other_verbs(doc, root_token)\n",
        "    token_spans = []\n",
        "    # Find the token span for each of the other verbs\n",
        "    all_verbs = [root_token] + other_verbs\n",
        "    for other_verb in all_verbs:\n",
        "        (first_token_index, last_token_index) = get_clause_token_span_for_verb(other_verb, doc, all_verbs)\n",
        "        token_spans.append((first_token_index, last_token_index))\n",
        "    sentence_clauses = []\n",
        "    for token_span in token_spans:\n",
        "        start = token_span[0]\n",
        "        end = token_span[1]\n",
        "        if (start < end):\n",
        "            clause = doc[start:end]\n",
        "            #if (potential_clause_contains_subj(clause)):\n",
        "            sentence_clauses.append(clause)\n",
        "    sentence_clauses = sorted(sentence_clauses, key=lambda tup: tup[0])\n",
        "    return sentence_clauses\n",
        "\n",
        "def main():\n",
        "    clauses = get_clauses(complex_sentence)\n",
        "    clauses_text = [clause.text for clause in clauses]\n",
        "    print(clauses_text)\n",
        "\n",
        "if (__name__ == \"__main__\"):\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fcdy5jqw8X9",
        "outputId": "a568a49e-ed63-4f5d-8b26-d5757e645bcd"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If \t 0 \t SCONJ \t mark \t ['rains', 'be'] \t []\n",
            "it \t 1 \t PRON \t nsubj \t ['rains', 'be'] \t []\n",
            "rains \t 2 \t VERB \t advcl \t ['be'] \t ['If', 'it', 'later']\n",
            "later \t 3 \t ADV \t advmod \t ['rains', 'be'] \t []\n",
            ", \t 4 \t PUNCT \t punct \t ['be'] \t []\n",
            "we \t 5 \t PRON \t nsubj \t ['be'] \t []\n",
            "wo \t 6 \t AUX \t aux \t ['be'] \t []\n",
            "n't \t 7 \t PART \t neg \t ['be'] \t []\n",
            "be \t 8 \t AUX \t ROOT \t [] \t ['rains', ',', 'we', 'wo', \"n't\", 'able', '.']\n",
            "able \t 9 \t ADJ \t acomp \t ['be'] \t ['go']\n",
            "to \t 10 \t PART \t aux \t ['go', 'able', 'be'] \t []\n",
            "go \t 11 \t VERB \t xcomp \t ['able', 'be'] \t ['to', 'to']\n",
            "to \t 12 \t ADP \t prep \t ['go', 'able', 'be'] \t ['park']\n",
            "the \t 13 \t DET \t det \t ['park', 'to', 'go', 'able', 'be'] \t []\n",
            "park \t 14 \t NOUN \t pobj \t ['to', 'go', 'able', 'be'] \t ['the']\n",
            ". \t 15 \t PUNCT \t punct \t ['be'] \t []\n",
            "['If it rains', \", we won't be able to go to the park\"]\n"
          ]
        }
      ]
    }
  ]
}